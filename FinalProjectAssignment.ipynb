{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Predict whether a mammogram mass is benign or malignant\n",
    "\n",
    "We'll be using the \"mammographic masses\" public dataset from the UCI repository (source: https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass)\n",
    "\n",
    "This data contains 961 instances of masses detected in mammograms, and contains the following attributes:\n",
    "\n",
    "\n",
    "   1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
    "   2. Age: patient's age in years (integer)\n",
    "   3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
    "   4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
    "   5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
    "   6. Severity: benign=0 or malignant=1 (binominal)\n",
    "   \n",
    "BI-RADS is an assesment of how confident the severity classification is; it is not a \"predictive\" attribute and so we will discard it. The age, shape, margin, and density attributes are the features that we will build our model with, and \"severity\" is the classification we will attempt to predict based on those attributes.\n",
    "\n",
    "Although \"shape\" and \"margin\" are nominal data types, which sklearn typically doesn't deal with well, they are close enough to ordinal that we shouldn't just discard them. The \"shape\" for example is ordered increasingly from round to irregular.\n",
    "\n",
    "A lot of unnecessary anguish and surgery arises from false positives arising from mammogram results. If we can build a better way to interpret them through supervised machine learning, it could improve a lot of lives.\n",
    "\n",
    "## Your assignment\n",
    "\n",
    "Apply several different supervised machine learning techniques to this data set, and see which one yields the highest accuracy as measured with K-Fold cross validation (K=10). Apply:\n",
    "\n",
    "* Decision tree\n",
    "* Random forest\n",
    "* KNN\n",
    "* Naive Bayes\n",
    "* SVM\n",
    "* Logistic Regression\n",
    "* And, as a bonus challenge, a neural network using Keras.\n",
    "\n",
    "The data needs to be cleaned; many rows contain missing data, and there may be erroneous data identifiable as outliers as well.\n",
    "\n",
    "Remember some techniques such as SVM also require the input data to be normalized first.\n",
    "\n",
    "Many techniques also have \"hyperparameters\" that need to be tuned. Once you identify a promising approach, see if you can make it even better by tuning its hyperparameters.\n",
    "\n",
    "I was able to achieve over 80% accuracy - can you beat that?\n",
    "\n",
    "Below I've set up an outline of a notebook for this project, with some guidance and hints. If you're up for a real challenge, try doing this project from scratch in a new, clean notebook!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's begin: prepare your data\n",
    "\n",
    "Start by importing the mammographic_masses.data.txt file into a Pandas dataframe (hint: use read_csv) and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI_RADS   age  shape  margin  density  severity\n",
       "0      5.0  67.0    3.0     5.0      3.0         1\n",
       "1      4.0  43.0    1.0     1.0      NaN         1\n",
       "2      5.0  58.0    4.0     5.0      3.0         1\n",
       "3      4.0  28.0    1.0     1.0      3.0         0\n",
       "4      5.0  74.0    1.0     5.0      NaN         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature_names = [\"BI_RADS\", \"age\", \"shape\", \"margin\", \"density\", \"severity\"]\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/amontagut/Desktop/Python/MLCourse/mammographic_masses.data.txt\", sep=\",\", na_values=['?'],\n",
    "                  names = feature_names)\n",
    "\n",
    "#Severity is a measure of malignancy. 0 = benign, 1 = malignant\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you use the optional parmaters in read_csv to convert missing data (indicated by a ?) into NaN, and to add the appropriate column names (BI_RADS, age, shape, margin, density, and severity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate whether the data needs cleaning; your model is only as good as the data it's given. Hint: use describe() on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.columns[1]].isna()==True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few missing values in the data set. Before we just drop every row that's missing data, let's make sure we don't bias our data in doing so. Does there appear to be any sort of correlation to what sort of data has missing fields? If there were, we'd have to try and go back and fill that data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI_RADS has this many NA's:  2\n",
      "age has this many NA's:  5\n",
      "shape has this many NA's:  31\n",
      "margin has this many NA's:  48\n",
      "density has this many NA's:  76\n",
      "severity has this many NA's:  0\n"
     ]
    }
   ],
   "source": [
    "#Iterate through all columns and return the number of affected rows\n",
    "\n",
    "for x in range(len(data.columns)):\n",
    "    print(data.columns[x], \"has this many NA's: \", len(data[data[data.columns[x]].isna()==True]))\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the missing data seems randomly distributed, go ahead and drop rows with missing data. Hint: use dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.393976</td>\n",
       "      <td>55.781928</td>\n",
       "      <td>2.781928</td>\n",
       "      <td>2.813253</td>\n",
       "      <td>2.915663</td>\n",
       "      <td>0.485542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.888371</td>\n",
       "      <td>14.671782</td>\n",
       "      <td>1.242361</td>\n",
       "      <td>1.567175</td>\n",
       "      <td>0.350936</td>\n",
       "      <td>0.500092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BI_RADS         age       shape      margin     density    severity\n",
       "count  830.000000  830.000000  830.000000  830.000000  830.000000  830.000000\n",
       "mean     4.393976   55.781928    2.781928    2.813253    2.915663    0.485542\n",
       "std      1.888371   14.671782    1.242361    1.567175    0.350936    0.500092\n",
       "min      0.000000   18.000000    1.000000    1.000000    1.000000    0.000000\n",
       "25%      4.000000   46.000000    2.000000    1.000000    3.000000    0.000000\n",
       "50%      4.000000   57.000000    3.000000    3.000000    3.000000    0.000000\n",
       "75%      5.000000   66.000000    4.000000    4.000000    3.000000    1.000000\n",
       "max     55.000000   96.000000    4.000000    5.000000    4.000000    1.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The instructor did drop the NA's, so I will too\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next you'll need to convert the Pandas dataframes into numpy arrays that can be used by scikit_learn. Create an array that extracts only the feature data we want to work with (age, shape, margin, and density) and another array that contains the classes (severity). You'll also need an array of the feature name labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(data[[\"age\", \"shape\", \"margin\", \"density\"]])\n",
    "\n",
    "y_data = np.array(data[\"severity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our models require the input data to be normalized, so go ahead and normalize the attribute data. Hint: use preprocessing.StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_data_fitted = scaler.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "Before moving to K-Fold cross validation and random forests, start by creating a single train/test split of our data. Set aside 75% for training, and 25% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_fitted, y_data, train_size=0.75)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a DecisionTreeClassifier and fit it to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the resulting decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(131.040087890625, 211.7178947368421, 'X[2] <= -0.838\\ngini = 0.498\\nsamples = 622\\nvalue = [330, 292]'),\n",
       " Text(56.57127403846154, 200.2736842105263, 'X[0] <= 0.595\\ngini = 0.219\\nsamples = 248\\nvalue = [217, 31]'),\n",
       " Text(21.931009615384614, 188.82947368421054, 'X[0] <= -0.974\\ngini = 0.168\\nsamples = 216\\nvalue = [196, 20]'),\n",
       " Text(4.292307692307692, 177.38526315789474, 'X[0] <= -1.52\\ngini = 0.051\\nsamples = 77\\nvalue = [75, 2]'),\n",
       " Text(2.146153846153846, 165.94105263157894, 'gini = 0.0\\nsamples = 41\\nvalue = [41, 0]'),\n",
       " Text(6.438461538461539, 165.94105263157894, 'X[0] <= -1.383\\ngini = 0.105\\nsamples = 36\\nvalue = [34, 2]'),\n",
       " Text(4.292307692307692, 154.49684210526317, 'X[1] <= -1.032\\ngini = 0.32\\nsamples = 10\\nvalue = [8, 2]'),\n",
       " Text(2.146153846153846, 143.05263157894737, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(6.438461538461539, 143.05263157894737, 'X[3] <= -1.185\\ngini = 0.408\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(4.292307692307692, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(8.584615384615384, 131.60842105263157, 'X[0] <= -1.451\\ngini = 0.444\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(6.438461538461539, 120.16421052631578, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(10.73076923076923, 120.16421052631578, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(8.584615384615384, 154.49684210526317, 'gini = 0.0\\nsamples = 26\\nvalue = [26, 0]'),\n",
       " Text(39.56971153846154, 177.38526315789474, 'X[0] <= -0.838\\ngini = 0.225\\nsamples = 139\\nvalue = [121, 18]'),\n",
       " Text(17.16923076923077, 165.94105263157894, 'X[3] <= -4.036\\ngini = 0.375\\nsamples = 20\\nvalue = [15, 5]'),\n",
       " Text(15.023076923076923, 154.49684210526317, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(19.315384615384616, 154.49684210526317, 'X[3] <= -1.185\\ngini = 0.332\\nsamples = 19\\nvalue = [15, 4]'),\n",
       " Text(17.16923076923077, 143.05263157894737, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(21.46153846153846, 143.05263157894737, 'X[1] <= -1.032\\ngini = 0.375\\nsamples = 16\\nvalue = [12, 4]'),\n",
       " Text(17.16923076923077, 131.60842105263157, 'X[0] <= -0.906\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(15.023076923076923, 120.16421052631578, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(19.315384615384616, 120.16421052631578, 'gini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(25.753846153846155, 131.60842105263157, 'X[0] <= -0.906\\ngini = 0.444\\nsamples = 9\\nvalue = [6, 3]'),\n",
       " Text(23.607692307692307, 120.16421052631578, 'gini = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(27.9, 120.16421052631578, 'gini = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(61.97019230769231, 165.94105263157894, 'X[1] <= -0.227\\ngini = 0.195\\nsamples = 119\\nvalue = [106, 13]'),\n",
       " Text(50.97115384615385, 154.49684210526317, 'X[0] <= 0.117\\ngini = 0.164\\nsamples = 111\\nvalue = [101, 10]'),\n",
       " Text(40.776923076923076, 143.05263157894737, 'X[0] <= -0.087\\ngini = 0.112\\nsamples = 84\\nvalue = [79, 5]'),\n",
       " Text(38.63076923076923, 131.60842105263157, 'X[0] <= -0.224\\ngini = 0.134\\nsamples = 69\\nvalue = [64, 5]'),\n",
       " Text(32.19230769230769, 120.16421052631578, 'X[0] <= -0.428\\ngini = 0.075\\nsamples = 51\\nvalue = [49, 2]'),\n",
       " Text(30.046153846153846, 108.72, 'X[0] <= -0.497\\ngini = 0.095\\nsamples = 40\\nvalue = [38, 2]'),\n",
       " Text(25.753846153846155, 97.27578947368421, 'X[0] <= -0.701\\ngini = 0.059\\nsamples = 33\\nvalue = [32, 1]'),\n",
       " Text(23.607692307692307, 85.83157894736843, 'X[1] <= -1.032\\ngini = 0.124\\nsamples = 15\\nvalue = [14, 1]'),\n",
       " Text(21.46153846153846, 74.38736842105263, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(25.753846153846155, 74.38736842105263, 'X[0] <= -0.769\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(23.607692307692307, 62.943157894736856, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(27.9, 62.943157894736856, 'X[3] <= -1.185\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(25.753846153846155, 51.49894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(30.046153846153846, 51.49894736842106, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(27.9, 85.83157894736843, 'gini = 0.0\\nsamples = 18\\nvalue = [18, 0]'),\n",
       " Text(34.33846153846154, 97.27578947368421, 'X[1] <= -1.032\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(32.19230769230769, 85.83157894736843, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(36.48461538461538, 85.83157894736843, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(34.33846153846154, 108.72, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(45.06923076923077, 120.16421052631578, 'X[3] <= -1.185\\ngini = 0.278\\nsamples = 18\\nvalue = [15, 3]'),\n",
       " Text(42.92307692307692, 108.72, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(47.215384615384615, 108.72, 'X[0] <= -0.156\\ngini = 0.291\\nsamples = 17\\nvalue = [14, 3]'),\n",
       " Text(42.92307692307692, 97.27578947368421, 'X[1] <= -1.032\\ngini = 0.32\\nsamples = 10\\nvalue = [8, 2]'),\n",
       " Text(40.776923076923076, 85.83157894736843, 'gini = 0.444\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(45.06923076923077, 85.83157894736843, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(51.50769230769231, 97.27578947368421, 'X[1] <= -1.032\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(49.36153846153846, 85.83157894736843, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(53.65384615384615, 85.83157894736843, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(42.92307692307692, 131.60842105263157, 'gini = 0.0\\nsamples = 15\\nvalue = [15, 0]'),\n",
       " Text(61.16538461538461, 143.05263157894737, 'X[0] <= 0.39\\ngini = 0.302\\nsamples = 27\\nvalue = [22, 5]'),\n",
       " Text(59.01923076923077, 131.60842105263157, 'X[0] <= 0.185\\ngini = 0.444\\nsamples = 15\\nvalue = [10, 5]'),\n",
       " Text(53.65384615384615, 120.16421052631578, 'X[1] <= -1.032\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(51.50769230769231, 108.72, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(55.8, 108.72, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(64.38461538461539, 120.16421052631578, 'X[0] <= 0.254\\ngini = 0.48\\nsamples = 10\\nvalue = [6, 4]'),\n",
       " Text(60.09230769230769, 108.72, 'X[1] <= -1.032\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(57.94615384615384, 97.27578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(62.238461538461536, 97.27578947368421, 'gini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(68.67692307692307, 108.72, 'X[1] <= -1.032\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(66.53076923076922, 97.27578947368421, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(70.82307692307693, 97.27578947368421, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(63.31153846153846, 131.60842105263157, 'gini = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(72.96923076923076, 154.49684210526317, 'X[0] <= 0.151\\ngini = 0.469\\nsamples = 8\\nvalue = [5, 3]'),\n",
       " Text(70.82307692307693, 143.05263157894737, 'X[0] <= -0.769\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(68.67692307692307, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(72.96923076923076, 131.60842105263157, 'X[0] <= -0.565\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(70.82307692307693, 120.16421052631578, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(75.11538461538461, 120.16421052631578, 'X[0] <= -0.224\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(72.96923076923076, 108.72, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(77.26153846153846, 108.72, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(75.11538461538461, 143.05263157894737, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(91.21153846153845, 188.82947368421054, 'X[1] <= -1.032\\ngini = 0.451\\nsamples = 32\\nvalue = [21, 11]'),\n",
       " Text(85.84615384615384, 177.38526315789474, 'X[0] <= 1.379\\ngini = 0.5\\nsamples = 16\\nvalue = [8, 8]'),\n",
       " Text(83.7, 165.94105263157894, 'X[3] <= -1.185\\ngini = 0.473\\nsamples = 13\\nvalue = [5, 8]'),\n",
       " Text(81.55384615384615, 154.49684210526317, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(85.84615384615384, 154.49684210526317, 'X[0] <= 0.867\\ngini = 0.496\\nsamples = 11\\nvalue = [5, 6]'),\n",
       " Text(83.7, 143.05263157894737, 'X[0] <= 0.663\\ngini = 0.48\\nsamples = 10\\nvalue = [4, 6]'),\n",
       " Text(81.55384615384615, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(85.84615384615384, 131.60842105263157, 'X[0] <= 0.799\\ngini = 0.494\\nsamples = 9\\nvalue = [4, 5]'),\n",
       " Text(83.7, 120.16421052631578, 'X[0] <= 0.731\\ngini = 0.48\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(81.55384615384615, 108.72, 'gini = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(85.84615384615384, 108.72, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(87.99230769230769, 120.16421052631578, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(87.99230769230769, 143.05263157894737, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(87.99230769230769, 165.94105263157894, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(96.57692307692308, 177.38526315789474, 'X[0] <= 1.208\\ngini = 0.305\\nsamples = 16\\nvalue = [13, 3]'),\n",
       " Text(92.28461538461538, 165.94105263157894, 'X[1] <= 0.578\\ngini = 0.142\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(90.13846153846154, 154.49684210526317, 'gini = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(94.43076923076923, 154.49684210526317, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(100.86923076923077, 165.94105263157894, 'X[3] <= -1.185\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(98.72307692307692, 154.49684210526317, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(103.01538461538462, 154.49684210526317, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(205.50890174278845, 200.2736842105263, 'X[0] <= 0.117\\ngini = 0.422\\nsamples = 374\\nvalue = [113, 261]'),\n",
       " Text(135.27056790865385, 188.82947368421054, 'X[1] <= 0.578\\ngini = 0.497\\nsamples = 152\\nvalue = [70, 82]'),\n",
       " Text(118.575, 177.38526315789474, 'X[0] <= -0.087\\ngini = 0.42\\nsamples = 50\\nvalue = [35, 15]'),\n",
       " Text(112.67307692307692, 165.94105263157894, 'X[0] <= -0.769\\ngini = 0.361\\nsamples = 38\\nvalue = [29, 9]'),\n",
       " Text(107.3076923076923, 154.49684210526317, 'X[1] <= -0.227\\ngini = 0.465\\nsamples = 19\\nvalue = [12, 7]'),\n",
       " Text(103.01538461538462, 143.05263157894737, 'X[2] <= 0.438\\ngini = 0.355\\nsamples = 13\\nvalue = [10, 3]'),\n",
       " Text(100.86923076923077, 131.60842105263157, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(105.16153846153846, 131.60842105263157, 'X[3] <= -1.185\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(103.01538461538462, 120.16421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(107.3076923076923, 120.16421052631578, 'X[0] <= -1.315\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(105.16153846153846, 108.72, 'X[0] <= -1.486\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(103.01538461538462, 97.27578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(107.3076923076923, 97.27578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(109.45384615384614, 108.72, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(111.6, 143.05263157894737, 'X[2] <= 0.438\\ngini = 0.444\\nsamples = 6\\nvalue = [2, 4]'),\n",
       " Text(109.45384615384614, 131.60842105263157, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(113.74615384615385, 131.60842105263157, 'X[0] <= -1.008\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(111.6, 120.16421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(115.89230769230768, 120.16421052631578, 'X[3] <= -1.185\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(113.74615384615385, 108.72, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(118.03846153846153, 108.72, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(118.03846153846153, 154.49684210526317, 'X[2] <= 1.077\\ngini = 0.188\\nsamples = 19\\nvalue = [17, 2]'),\n",
       " Text(115.89230769230768, 143.05263157894737, 'gini = 0.0\\nsamples = 16\\nvalue = [16, 0]'),\n",
       " Text(120.18461538461538, 143.05263157894737, 'X[1] <= -0.63\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(118.03846153846153, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(122.33076923076922, 131.60842105263157, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(124.47692307692307, 165.94105263157894, 'X[2] <= 0.438\\ngini = 0.5\\nsamples = 12\\nvalue = [6, 6]'),\n",
       " Text(122.33076923076922, 154.49684210526317, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(126.62307692307692, 154.49684210526317, 'X[1] <= -1.032\\ngini = 0.444\\nsamples = 9\\nvalue = [6, 3]'),\n",
       " Text(124.47692307692307, 143.05263157894737, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(128.76923076923077, 143.05263157894737, 'X[0] <= 0.049\\ngini = 0.375\\nsamples = 8\\nvalue = [6, 2]'),\n",
       " Text(126.62307692307692, 131.60842105263157, 'X[3] <= -1.185\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(124.47692307692307, 120.16421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(128.76923076923077, 120.16421052631578, 'X[1] <= -0.227\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(126.62307692307692, 108.72, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(130.91538461538462, 108.72, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(130.91538461538462, 131.60842105263157, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(151.96613581730767, 177.38526315789474, 'X[0] <= -1.383\\ngini = 0.451\\nsamples = 102\\nvalue = [35, 67]'),\n",
       " Text(133.06153846153845, 165.94105263157894, 'X[3] <= -1.185\\ngini = 0.408\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(130.91538461538462, 154.49684210526317, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(135.2076923076923, 154.49684210526317, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(170.87073317307693, 165.94105263157894, 'X[0] <= -0.769\\ngini = 0.432\\nsamples = 95\\nvalue = [30, 65]'),\n",
       " Text(139.5, 154.49684210526317, 'X[0] <= -1.213\\ngini = 0.278\\nsamples = 18\\nvalue = [3, 15]'),\n",
       " Text(137.35384615384615, 143.05263157894737, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(141.64615384615385, 143.05263157894737, 'X[0] <= -1.11\\ngini = 0.32\\nsamples = 15\\nvalue = [3, 12]'),\n",
       " Text(139.5, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(143.79230769230767, 131.60842105263157, 'X[0] <= -0.974\\ngini = 0.245\\nsamples = 14\\nvalue = [2, 12]'),\n",
       " Text(141.64615384615385, 120.16421052631578, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(145.93846153846152, 120.16421052631578, 'X[2] <= 0.438\\ngini = 0.32\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " Text(143.79230769230767, 108.72, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(148.08461538461538, 108.72, 'X[3] <= -1.185\\ngini = 0.375\\nsamples = 8\\nvalue = [2, 6]'),\n",
       " Text(145.93846153846152, 97.27578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(150.23076923076923, 97.27578947368421, 'X[0] <= -0.872\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 5]'),\n",
       " Text(145.93846153846152, 85.83157894736843, 'X[2] <= 1.077\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(143.79230769230767, 74.38736842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(148.08461538461538, 74.38736842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(154.52307692307693, 85.83157894736843, 'X[2] <= 1.077\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(152.37692307692308, 74.38736842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(156.66923076923075, 74.38736842105263, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(202.24146634615383, 154.49684210526317, 'X[3] <= -1.185\\ngini = 0.455\\nsamples = 77\\nvalue = [27, 50]'),\n",
       " Text(200.0953125, 143.05263157894737, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(204.38762019230768, 143.05263157894737, 'X[3] <= 1.666\\ngini = 0.463\\nsamples = 74\\nvalue = [27, 47]'),\n",
       " Text(202.24146634615383, 131.60842105263157, 'X[0] <= -0.019\\ngini = 0.471\\nsamples = 71\\nvalue = [27, 44]'),\n",
       " Text(190.94062499999998, 120.16421052631578, 'X[0] <= -0.156\\ngini = 0.455\\nsamples = 60\\nvalue = [21, 39]'),\n",
       " Text(181.21586538461537, 108.72, 'X[0] <= -0.224\\ngini = 0.476\\nsamples = 46\\nvalue = [18, 28]'),\n",
       " Text(174.64326923076922, 97.27578947368421, 'X[0] <= -0.292\\ngini = 0.444\\nsamples = 39\\nvalue = [13, 26]'),\n",
       " Text(167.93653846153845, 85.83157894736843, 'X[2] <= 1.077\\ngini = 0.48\\nsamples = 30\\nvalue = [12, 18]'),\n",
       " Text(160.96153846153845, 74.38736842105263, 'X[2] <= -0.2\\ngini = 0.499\\nsamples = 21\\nvalue = [10, 11]'),\n",
       " Text(158.8153846153846, 62.943157894736856, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(163.1076923076923, 62.943157894736856, 'X[0] <= -0.701\\ngini = 0.5\\nsamples = 20\\nvalue = [10, 10]'),\n",
       " Text(160.96153846153845, 51.49894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(165.25384615384615, 51.49894736842106, 'X[0] <= -0.497\\ngini = 0.499\\nsamples = 19\\nvalue = [9, 10]'),\n",
       " Text(157.7423076923077, 40.05473684210526, 'X[2] <= 0.438\\ngini = 0.469\\nsamples = 8\\nvalue = [3, 5]'),\n",
       " Text(155.59615384615384, 28.610526315789485, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(159.88846153846154, 28.610526315789485, 'X[0] <= -0.633\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 5]'),\n",
       " Text(157.7423076923077, 17.166315789473686, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(162.0346153846154, 17.166315789473686, 'X[0] <= -0.565\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(159.88846153846154, 5.722105263157886, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(164.18076923076922, 5.722105263157886, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(172.76538461538462, 40.05473684210526, 'X[0] <= -0.428\\ngini = 0.496\\nsamples = 11\\nvalue = [6, 5]'),\n",
       " Text(170.61923076923077, 28.610526315789485, 'gini = 0.444\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(174.91153846153844, 28.610526315789485, 'X[2] <= 0.438\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(170.61923076923077, 17.166315789473686, 'X[0] <= -0.36\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(168.47307692307692, 5.722105263157886, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(172.76538461538462, 5.722105263157886, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(179.20384615384614, 17.166315789473686, 'X[0] <= -0.36\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(177.0576923076923, 5.722105263157886, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(181.35, 5.722105263157886, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(174.91153846153844, 74.38736842105263, 'X[0] <= -0.633\\ngini = 0.346\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(172.76538461538462, 62.943157894736856, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(177.0576923076923, 62.943157894736856, 'X[0] <= -0.531\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 5]'),\n",
       " Text(174.91153846153844, 51.49894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(179.20384615384614, 51.49894736842106, 'X[0] <= -0.428\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(177.0576923076923, 40.05473684210526, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(181.35, 40.05473684210526, 'X[0] <= -0.36\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(179.20384615384614, 28.610526315789485, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(183.49615384615385, 28.610526315789485, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(181.35, 85.83157894736843, 'X[2] <= 1.077\\ngini = 0.198\\nsamples = 9\\nvalue = [1, 8]'),\n",
       " Text(179.20384615384614, 74.38736842105263, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
       " Text(183.49615384615385, 74.38736842105263, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(187.78846153846152, 97.27578947368421, 'X[2] <= 0.438\\ngini = 0.408\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(185.6423076923077, 85.83157894736843, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(189.93461538461537, 85.83157894736843, 'X[2] <= 1.077\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(187.78846153846152, 74.38736842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(192.08076923076922, 74.38736842105263, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(200.6653846153846, 108.72, 'X[2] <= 0.438\\ngini = 0.337\\nsamples = 14\\nvalue = [3, 11]'),\n",
       " Text(196.37307692307692, 97.27578947368421, 'X[0] <= -0.087\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(194.22692307692307, 85.83157894736843, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(198.51923076923077, 85.83157894736843, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(204.9576923076923, 97.27578947368421, 'X[0] <= -0.087\\ngini = 0.278\\nsamples = 12\\nvalue = [2, 10]'),\n",
       " Text(202.81153846153845, 85.83157894736843, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(207.10384615384615, 85.83157894736843, 'X[2] <= 1.077\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 5]'),\n",
       " Text(204.9576923076923, 74.38736842105263, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(209.25, 74.38736842105263, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(213.54230769230767, 120.16421052631578, 'X[2] <= 1.077\\ngini = 0.496\\nsamples = 11\\nvalue = [6, 5]'),\n",
       " Text(211.39615384615385, 108.72, 'X[0] <= 0.049\\ngini = 0.444\\nsamples = 9\\nvalue = [6, 3]'),\n",
       " Text(209.25, 97.27578947368421, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(213.54230769230767, 97.27578947368421, 'X[2] <= 0.438\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(211.39615384615385, 85.83157894736843, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(215.68846153846152, 85.83157894736843, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(215.68846153846152, 108.72, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(206.53377403846153, 131.60842105263157, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(275.74723557692306, 188.82947368421054, 'X[0] <= 0.936\\ngini = 0.312\\nsamples = 222\\nvalue = [43, 179]'),\n",
       " Text(244.72860576923077, 177.38526315789474, 'X[1] <= 0.578\\ngini = 0.388\\nsamples = 129\\nvalue = [34, 95]'),\n",
       " Text(226.41923076923075, 165.94105263157894, 'X[2] <= 0.438\\ngini = 0.478\\nsamples = 33\\nvalue = [13, 20]'),\n",
       " Text(219.98076923076923, 154.49684210526317, 'X[1] <= -0.227\\ngini = 0.444\\nsamples = 9\\nvalue = [6, 3]'),\n",
       " Text(217.83461538461538, 143.05263157894737, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(222.12692307692308, 143.05263157894737, 'X[0] <= 0.663\\ngini = 0.49\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(219.98076923076923, 131.60842105263157, 'X[0] <= 0.526\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(217.83461538461538, 120.16421052631578, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(222.12692307692308, 120.16421052631578, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(224.27307692307693, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(232.8576923076923, 154.49684210526317, 'X[2] <= 1.077\\ngini = 0.413\\nsamples = 24\\nvalue = [7, 17]'),\n",
       " Text(230.71153846153845, 143.05263157894737, 'X[3] <= -4.036\\ngini = 0.465\\nsamples = 19\\nvalue = [7, 12]'),\n",
       " Text(228.5653846153846, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(232.8576923076923, 131.60842105263157, 'X[0] <= 0.595\\ngini = 0.444\\nsamples = 18\\nvalue = [6, 12]'),\n",
       " Text(228.5653846153846, 120.16421052631578, 'X[0] <= 0.185\\ngini = 0.5\\nsamples = 10\\nvalue = [5, 5]'),\n",
       " Text(226.41923076923075, 108.72, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(230.71153846153845, 108.72, 'X[1] <= -1.032\\ngini = 0.494\\nsamples = 9\\nvalue = [5, 4]'),\n",
       " Text(228.5653846153846, 97.27578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(232.8576923076923, 97.27578947368421, 'X[0] <= 0.288\\ngini = 0.5\\nsamples = 8\\nvalue = [4, 4]'),\n",
       " Text(230.71153846153845, 85.83157894736843, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(235.00384615384615, 85.83157894736843, 'X[0] <= 0.39\\ngini = 0.49\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(230.71153846153845, 74.38736842105263, 'X[1] <= -0.227\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(228.5653846153846, 62.943157894736856, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(232.8576923076923, 62.943157894736856, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(239.29615384615383, 74.38736842105263, 'X[1] <= -0.227\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(237.15, 62.943157894736856, 'X[0] <= 0.492\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(235.00384615384615, 51.49894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(239.29615384615383, 51.49894736842106, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(241.44230769230768, 62.943157894736856, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(237.15, 120.16421052631578, 'X[0] <= 0.833\\ngini = 0.219\\nsamples = 8\\nvalue = [1, 7]'),\n",
       " Text(235.00384615384615, 108.72, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(239.29615384615383, 108.72, 'X[1] <= -0.227\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(237.15, 97.27578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(241.44230769230768, 97.27578947368421, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(235.00384615384615, 143.05263157894737, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(263.0379807692308, 165.94105263157894, 'X[2] <= -0.2\\ngini = 0.342\\nsamples = 96\\nvalue = [21, 75]'),\n",
       " Text(260.8918269230769, 154.49684210526317, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(265.1841346153846, 154.49684210526317, 'X[3] <= 1.666\\ngini = 0.332\\nsamples = 95\\nvalue = [20, 75]'),\n",
       " Text(263.0379807692308, 143.05263157894737, 'X[0] <= 0.867\\ngini = 0.323\\nsamples = 94\\nvalue = [19, 75]'),\n",
       " Text(258.7456730769231, 131.60842105263157, 'X[3] <= -1.185\\ngini = 0.315\\nsamples = 92\\nvalue = [18, 74]'),\n",
       " Text(256.5995192307692, 120.16421052631578, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(260.8918269230769, 120.16421052631578, 'X[0] <= 0.185\\ngini = 0.325\\nsamples = 88\\nvalue = [18, 70]'),\n",
       " Text(247.88076923076923, 108.72, 'X[2] <= 0.438\\ngini = 0.444\\nsamples = 9\\nvalue = [3, 6]'),\n",
       " Text(245.73461538461538, 97.27578947368421, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(250.02692307692305, 97.27578947368421, 'X[2] <= 1.077\\ngini = 0.375\\nsamples = 8\\nvalue = [2, 6]'),\n",
       " Text(247.88076923076923, 85.83157894736843, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(252.1730769230769, 85.83157894736843, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(273.9028846153846, 108.72, 'X[2] <= 1.077\\ngini = 0.308\\nsamples = 79\\nvalue = [15, 64]'),\n",
       " Text(262.3673076923077, 97.27578947368421, 'X[0] <= 0.663\\ngini = 0.329\\nsamples = 53\\nvalue = [11, 42]'),\n",
       " Text(256.4653846153846, 85.83157894736843, 'X[0] <= 0.595\\ngini = 0.375\\nsamples = 32\\nvalue = [8, 24]'),\n",
       " Text(251.1, 74.38736842105263, 'X[0] <= 0.39\\ngini = 0.346\\nsamples = 27\\nvalue = [6, 21]'),\n",
       " Text(246.8076923076923, 62.943157894736856, 'X[0] <= 0.322\\ngini = 0.298\\nsamples = 11\\nvalue = [2, 9]'),\n",
       " Text(244.66153846153844, 51.49894736842106, 'X[0] <= 0.254\\ngini = 0.32\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " Text(240.36923076923077, 40.05473684210526, 'X[2] <= 0.438\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(238.22307692307692, 28.610526315789485, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(242.51538461538462, 28.610526315789485, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(248.95384615384614, 40.05473684210526, 'X[2] <= 0.438\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(246.8076923076923, 28.610526315789485, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(251.1, 28.610526315789485, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(248.95384615384614, 51.49894736842106, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(255.3923076923077, 62.943157894736856, 'X[2] <= 0.438\\ngini = 0.375\\nsamples = 16\\nvalue = [4, 12]'),\n",
       " Text(253.24615384615385, 51.49894736842106, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(257.53846153846155, 51.49894736842106, 'X[0] <= 0.458\\ngini = 0.408\\nsamples = 14\\nvalue = [4, 10]'),\n",
       " Text(255.3923076923077, 40.05473684210526, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(259.68461538461537, 40.05473684210526, 'X[0] <= 0.526\\ngini = 0.375\\nsamples = 12\\nvalue = [3, 9]'),\n",
       " Text(257.53846153846155, 28.610526315789485, 'gini = 0.375\\nsamples = 8\\nvalue = [2, 6]'),\n",
       " Text(261.83076923076925, 28.610526315789485, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(261.83076923076925, 74.38736842105263, 'X[2] <= 0.438\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(259.68461538461537, 62.943157894736856, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(263.9769230769231, 62.943157894736856, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(268.2692307692308, 85.83157894736843, 'X[0] <= 0.731\\ngini = 0.245\\nsamples = 21\\nvalue = [3, 18]'),\n",
       " Text(266.1230769230769, 74.38736842105263, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
       " Text(270.4153846153846, 74.38736842105263, 'X[2] <= 0.438\\ngini = 0.337\\nsamples = 14\\nvalue = [3, 11]'),\n",
       " Text(268.2692307692308, 62.943157894736856, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(272.5615384615385, 62.943157894736856, 'X[0] <= 0.799\\ngini = 0.42\\nsamples = 10\\nvalue = [3, 7]'),\n",
       " Text(270.4153846153846, 51.49894736842106, 'gini = 0.32\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(274.7076923076923, 51.49894736842106, 'gini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(285.4384615384615, 97.27578947368421, 'X[0] <= 0.663\\ngini = 0.26\\nsamples = 26\\nvalue = [4, 22]'),\n",
       " Text(281.1461538461538, 85.83157894736843, 'X[0] <= 0.322\\ngini = 0.117\\nsamples = 16\\nvalue = [1, 15]'),\n",
       " Text(279.0, 74.38736842105263, 'X[0] <= 0.254\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(276.8538461538461, 62.943157894736856, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(281.1461538461538, 62.943157894736856, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(283.2923076923077, 74.38736842105263, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 13]'),\n",
       " Text(289.7307692307692, 85.83157894736843, 'X[0] <= 0.731\\ngini = 0.42\\nsamples = 10\\nvalue = [3, 7]'),\n",
       " Text(287.58461538461535, 74.38736842105263, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(291.87692307692305, 74.38736842105263, 'X[0] <= 0.799\\ngini = 0.346\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(289.7307692307692, 62.943157894736856, 'gini = 0.444\\nsamples = 6\\nvalue = [2, 4]'),\n",
       " Text(294.0230769230769, 62.943157894736856, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(267.33028846153843, 131.60842105263157, 'X[2] <= 0.438\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(265.1841346153846, 120.16421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(269.4764423076923, 120.16421052631578, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(267.33028846153843, 143.05263157894737, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(306.7658653846154, 177.38526315789474, 'X[1] <= -0.227\\ngini = 0.175\\nsamples = 93\\nvalue = [9, 84]'),\n",
       " Text(290.80384615384617, 165.94105263157894, 'X[2] <= 0.438\\ngini = 0.42\\nsamples = 10\\nvalue = [3, 7]'),\n",
       " Text(286.51153846153846, 154.49684210526317, 'X[0] <= 1.038\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(284.3653846153846, 143.05263157894737, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(288.6576923076923, 143.05263157894737, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(295.0961538461538, 154.49684210526317, 'X[1] <= -1.032\\ngini = 0.245\\nsamples = 7\\nvalue = [1, 6]'),\n",
       " Text(292.95, 143.05263157894737, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(297.2423076923077, 143.05263157894737, 'X[0] <= 1.072\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(295.0961538461538, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(299.3884615384615, 131.60842105263157, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(322.7278846153846, 165.94105263157894, 'X[3] <= 1.666\\ngini = 0.134\\nsamples = 83\\nvalue = [6, 77]'),\n",
       " Text(314.94807692307694, 154.49684210526317, 'X[0] <= 1.89\\ngini = 0.116\\nsamples = 81\\nvalue = [5, 76]'),\n",
       " Text(305.8269230769231, 143.05263157894737, 'X[0] <= 1.413\\ngini = 0.087\\nsamples = 66\\nvalue = [3, 63]'),\n",
       " Text(303.6807692307692, 131.60842105263157, 'X[0] <= 1.004\\ngini = 0.124\\nsamples = 45\\nvalue = [3, 42]'),\n",
       " Text(301.5346153846154, 120.16421052631578, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(305.8269230769231, 120.16421052631578, 'X[0] <= 1.14\\ngini = 0.142\\nsamples = 39\\nvalue = [3, 36]'),\n",
       " Text(300.46153846153845, 108.72, 'X[2] <= 1.077\\ngini = 0.198\\nsamples = 18\\nvalue = [2, 16]'),\n",
       " Text(296.16923076923075, 97.27578947368421, 'X[0] <= 1.072\\ngini = 0.142\\nsamples = 13\\nvalue = [1, 12]'),\n",
       " Text(294.0230769230769, 85.83157894736843, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(298.31538461538463, 85.83157894736843, 'X[2] <= -0.2\\ngini = 0.245\\nsamples = 7\\nvalue = [1, 6]'),\n",
       " Text(296.16923076923075, 74.38736842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(300.46153846153845, 74.38736842105263, 'X[2] <= 0.438\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(298.31538461538463, 62.943157894736856, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(302.6076923076923, 62.943157894736856, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(304.75384615384615, 97.27578947368421, 'X[0] <= 1.072\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(302.6076923076923, 85.83157894736843, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(306.9, 85.83157894736843, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(311.1923076923077, 108.72, 'X[0] <= 1.345\\ngini = 0.091\\nsamples = 21\\nvalue = [1, 20]'),\n",
       " Text(309.04615384615386, 97.27578947368421, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 12]'),\n",
       " Text(313.3384615384615, 97.27578947368421, 'X[2] <= 0.438\\ngini = 0.198\\nsamples = 9\\nvalue = [1, 8]'),\n",
       " Text(311.1923076923077, 85.83157894736843, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(315.4846153846154, 85.83157894736843, 'X[2] <= 1.077\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(313.3384615384615, 74.38736842105263, 'gini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(317.6307692307692, 74.38736842105263, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(307.9730769230769, 131.60842105263157, 'gini = 0.0\\nsamples = 21\\nvalue = [0, 21]'),\n",
       " Text(324.0692307692308, 143.05263157894737, 'X[0] <= 2.095\\ngini = 0.231\\nsamples = 15\\nvalue = [2, 13]'),\n",
       " Text(321.9230769230769, 131.60842105263157, 'X[1] <= 0.578\\ngini = 0.346\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(319.7769230769231, 120.16421052631578, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(324.0692307692308, 120.16421052631578, 'X[2] <= 0.438\\ngini = 0.444\\nsamples = 6\\nvalue = [2, 4]'),\n",
       " Text(321.9230769230769, 108.72, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(326.2153846153846, 108.72, 'X[2] <= 1.077\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(321.9230769230769, 97.27578947368421, 'X[0] <= 2.027\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(319.7769230769231, 85.83157894736843, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(324.0692307692308, 85.83157894736843, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(330.5076923076923, 97.27578947368421, 'X[0] <= 1.993\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(328.36153846153843, 85.83157894736843, 'gini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(332.65384615384613, 85.83157894736843, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(326.2153846153846, 131.60842105263157, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(330.5076923076923, 154.49684210526317, 'X[0] <= 1.242\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(328.36153846153843, 143.05263157894737, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(332.65384615384613, 143.05263157894737, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADnCAYAAAAgo4yYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2deXxd11Xvv1vSHeTYsmVb8STZcjzGiR3HcWbXNtApgbTQAdoHpbS0hQJ9UMpQHo+xZZ5e6dzAa9IGaD9JSJpXoECBpLEzlDitk8axEsWW5UnyII+xrmRZ+/2xz7k+d999xjuce6X9+3zOR7r37L322muvs+65+561fkJKiYWFhYVF/dGStgIWFhYW0xU2AFtYWFikBBuALSwsLFKCDcAWFhYWKcEGYAsLC4uUYAOwhYWFRUqwAdjCwsIiJdgAbGFhYZESbAC28EV7e/uQEEJGOdrb24fS1tfCotkgbCachR+EEDKqfwghkFKKGqtkYTGl0Ja2AhaNjZ07d5LP51m0aBGXLl0im83S19eHG5i3bduWsoYWFs0LG4AtABBCCGAhsAZY6/xl3bp1PPzwwxw/fpxFixYxOjpKPp9HSsnSpUt1GXcBe4H9UsqJOk/BwqLpYAPwNIMQIg+sojTQuscY0OccewFeeOEFOjo6mDFjBmfOnGHNmjVMTEzQ39/PkSNHWLRokVf8zzlyFgsh9jsyvPL6pJQjdZmohUUTwO4BT0F47ma9Adb9fzEQKTgm3QMWQrQDKykP8mtRQb5sbGCfvWu2mG6wAbiJ4XM36/4tUB7kYm0PZLPZkxcvXpwbpW0+nx8eHR1dGKKvaZvD/d/9YNB17pNSnoyig4VFs8EG4AaHE7QWUX4n697N7sMctKr+VV8I0SmlPBX2XkLZedRds+mufRz/D5OLlY5tYZEWbABuEDhf2927WT3Qunez+lf3Kf9jl/MBtIDywOzeNQ9g3k6xd80WDQ8bgOsIz92s6S5vEZfvZr0Bxf5w5QPPXbNpS8N01+zuNdu7ZouGgA3ANYDnblYPCquBUcyBYcrfzdYLnrtm0974EtRds76dYe+aLeqOaRmA29vbhwqFwoKwdkE/LDkX+WLMd18LgVcw781WvF9qkRzaXbO+dhP4P6Hhe9cc1Z8g2o+VFtMH0zIAR328yn20ygm2X0EF1WVcvmAvYL5gB+zdbHPB567Z/d9713zAef8OKeWk09embFskwrQNwDt27EAIQW9vbzHFdmBggEKhQD6f5+abb/YG4LnAYeDLwE4uf2U9nepELOoCIUSOy09obAF+ErhKSnnGOS+llOzcubPMp4aGhjh9+jSLFy9m1apVNgBblGDaBuCRkREefvhhFi1aVEyxFUJQKBRYu3YtCxYssBeLRSiEEG3ARSklp06dKvOplpYWRkdHWb9+PXPnzrU+ZVGCaZWKLITIAq8F/xTbEydOsHfvXhYsiLSlZzFN4PjOKmCdc1zt/F3ltvHzqaGhIfbv38/cuXNdWa8Ae5zjRfevlPJcfWdlkTam/B2w8/Xx9cDbgLtQzn571D1g4DHgAeBBKeXR2mlq0QgQQsxA7fF6g+w61N7/AcoDZx/wapw9YNRWhh7I1wInPfKLY9jHEKcupmQAdn7pfgPwduAHgeeB+4F/lFIeFkLIgYEBDh06xMyZM5k/fz5DQ0N0dHSQzWY5cuQIS5cupbu7G+BNjpwfAl5w5DwopTycyuQsqgIhRAcq+HmD7DrU89gvUxpk9wAvSynHfWTJRx99lN7e3hKfOn36NBcuXODKK69kaGiIiYkJtmzZYtyCEEK0ooK8Vx/3/wuaLu7/w5F//bNoSEyZAOw8e/tGVLC8E/guKlg+JKU84m2b5DE05076tY78N6EuAjcYH6zmXCyqByHEPMrvZq8GOlE/pnoD2x4SPI9dy8fQnKczllD+QbEOEAb9XwQO2sDcHGjqAOx8XbwTtb3wRuBZLgfdmlHkOPuBP8DlYPwyapviASnlgVqNa2GGp8iP6e4xR/nd7IvAoPsYWTPCmXMX5g+XWag56sF5QEp5KRWFLYxougAshLgCta3wdtTe7rdRwe8hKeWxFPTJAN+P+hD4YVRFr/tRwXh/vfWZynCCTg/lQXYdcBHz1/Sj0+1uUAjRiXl7pQt4iXIb9dv07HTQFAFYCDGLy0H3tcBTqCD3sJTyRJq6eeEE420oPX8EGORyMH4lTd2aCc5+6HLMP1SdxfwEwfF0tG0eCCFmcvkHQG9w7kElGekfYH1SykI62k4PNHQAFkLcg3oAfj0qAeIB4GvNkLPvPB+6FRWM34JK5DgA/ImU8qk0dWsUOFs5KykPCKuAYQxbB27yg0X14PxovZryD7wVwEHK12GvlPJ8OtpOLdQtACf84esJ4HvArzdzDQXnju41qHTmr0gpf8k9F8UujVQ/IK6+zreCmZh/4V+O+pagX+B9UspXazYJi0hw1m4F5YF5DXCc8h//DqO2fIpPi1Sj7spURt0CcNz6C3VQqSEQxS6NZJO4+goh9qC+9r5A+Vfcl6SUY7XV2KLacG4oein/QL0JeEpKeaunrb3uA1DXTDhTrnxfXx+5XI5CoTBtKc737NnDnDlzijYZHh7mzJkzZLNZbr755rTVK8POnTvp7Ows0dmto2HA96M+6G0SyxSB8yTFK87xdfd9p2ZKmROYrvsDBw4ghGBycrIhfbxeqGsAdinOz549W8yVnzNnDqOjo6xevbqeqjQUnn766bL6Adlslk2bNqWtmhG7d+9m3bp1nDp1itbWVlpaWgC4/vrr6ejoKGlby8cBLRoLfhl7puteCFGskTGd0VLPwfRc+eXLlzNv3jzy+TyDg4P1VKWhsGrVKl599VXOnDnD+Pg4y5Yto7u7myeeeILJycZ7VHXDhg2cPHmSS5culei7e/duvvOd76StnkXKEAq3CCE+A+brvru7mzlz5rB//35vv96UVE4NddkDFkIsAo7YvaByNNMesBDiB4GvN4u+FvWFEGIp8C5UuU4BfAn4WIy6KydRZQO+hHp0c8oXJ6rpHbDzSfgeYHcmkxkVQhB25HI5KYT4sLPRP+WRyWRGwmySz+eH09RRCDFLCHE38KlMJnM24hp+ZLqs4XSG4xs/JYT4T1Qm6hLg3cAaKeXHo/i3x8eXAJ8E3gwcFELcJ4R43VT2o5rdAQshlgNfAOYCPy2l/K523khxDswH/gaVQvrTUsoXaqJgA0EI8bfAe53i752opwaeAK4EJtJ8BE8IsQ24B/gP4JellGe18yXr6Ojf6fSRwE/ZjMCpBScgfh8q0N4FfAu4F/XtKPCpFr/r3vBeF/AOZ4yFwN8B90op91RtIg2AqgdgIcRs4LdQhvtT4K/iFjcRQrQA7wf+GDgupZzSv9A5e1/zpZTPeN57M/BImmm0QohDQDvwbinl18Paa31bgQ8DH0Mlz7yjBipa1BFCiKtR2ws/ARxDbRX8Q61LAAghrkFtbbwLOIoK9l+ZCtmPtQjAnwE+iPoK8lKFsl4P/KqU8nVVUc4iFoQQ/wB8Ukr5RAUyPgTMlVL+XvU0s6gXhBDzUXeiPwl0A/cBX5JSfi8FXVpRjzW+G1Ue9lHUh8A/Nevz5A2dimxhYVF/ON9ifwW4FhXw/gl11/kfjUI269SHeRvqg2E98FUUecLDfnWbGxGRfoRrb28fEkLIoKO9vb0uz3tG0aWe+sRBmO6uzrWydyOsYzOvX7Migc1/HvjfqCSLHinl/5BS/mujBF8AKeU5KeUXpZTfB2xGbU18FfgTt00j+HsYIt0BiwZ6VCqKLvXUJw7CdHd1rpW9G2Edm3n9mhXTxeZCFcC65E62Efw9DJEz4UzphMPDw4yOjtadwNIvpdk1diOnND/xxBNFvdva2hgfH6dQKHD6dCnDvT5Ht+3Ro0cZG0u+3eVnu2w2S2dnZ6XTS6xDo6dfNzvC0scb+ZqJCtMdumnefX19zJo1i5kzZ6ahZgkiB2A3/XT//v20trYyPj5OLpdj06ZNZDKZWupYBlNqYy6XA2j4lOa+vr6ylExTwPFL3xwfH2fDhg2JxzfJzefzZDIZ1qxZU8nUKtKh0dOvmx2uzb0p70IlPzT8NVMJTPOeM2cOuVyO+fPnp61e9EQMPf10zZo1dHd3Mzg4SJSvN9WEX2rj5OQkL71U0YMXNYdJ7yeffJKLF0sJCfzmmMlkKvrkNsldsmQJk5OTFd1ZV0MHKSXPPvtsXXSYbghKB57KZQD8yh+cP3+eWbNmpa1e8+wBO7/Mfhj4nWbdz5rue8DO892XmnX9mhFC1fQdn442T9vfoyDyFsSBAwdKKLfPnz9PR0cH+/bt4/bbb6+Zgs7jJh9CBd9/MunS399PW1tbkV5+5cqVbt8HUAG7YbLpTLoDRZ1dPPbYY2U05/v372fFihUV3eXr4x86dIilS5dy/Phx5s2bV9HcgiCEuAH4LJjn5uoxODjIwoUL3T53Sin/uWZKTXEIIW5BZaMa133hwoUMDQ3R3d3NkiVL3D4LpJSppr5XA0KId4DZ19xrrq2tzW17g5RyVyqKSilDj3w+P4RKK/U98vn8UBRZUQ9gBvCrKGqav0MldkTSxdFn2NP/74HV1dQvyRGmu2vDWtk7pXXsBD4NDAHvibF+I0A/8BCwLO21a6YDmAN8BjgCvCOGzV9FZbi9H2hJex4J5z4L9cxyXz6fPxFhzqedOf9aGnOOO7kVqILLK4HfrZEB88AvoZ7rux+4pgoL8r9QFCr3AFc1gJNsQWULPgR8NqDd7wC/6Px/JfCfVRj7bcBenO0n572PAf9W5Tm2AD/lBN7PorLhkvjCb6OqZP0GkE177Rr5QFUg+1EUNdDngM4EMq4DngYeB9alPaeYc78DVST+C8AVMfouc+b7GHBHXfWOOckfBi7WyIA54OeAQ8DDwMYqy58N/K5zMX8B2NIATvMw8GzaetRgXh9C0Q59G9hcBXlXoZICLgDvS3t+jXg4AUg6Aei2CmW1OtfiGPDNtOcWUecfd+b/9oT921Bs66fqqXdDpCILIT4AfB74F+C3pacoTQ3Gmou6s/yfwHVSyudqNdZ0hRDiX1EO/Xqp6GuqJfduYIeU8t5qyZxKEEL8IfAJWaU9XCHEHUCXlPJL1ZBXSzhJGD2yySrvNUoA3gy8Tkr5R3UcsxM4LRvBABYWFtMSsQqyx8mtjtNWSvlMPYOvM+Ypb/CtVY2CiHa4VGkbr15xc+CrqGNd8+qnel2JRqtlkIa9o9ZPqQXqYf/AO+D29vahQqFQkme8Y8eOwDTSW265Bek8y/rUU0/R09NTwoQ6NjZWTDcVDfTcoRBC7tixIzBtcdWqVbF1duW2tbUVbXH77bdz8ODBknamsb2potu3b0e35/DwMBcuXEAIUbS7d0x9nfr6+mhvb2dyctLYPp/Ps2jRomL7oaEhCoUChUIhdPw01jPKPBvNz+Ig6rrUa27Cea52586dZTq518n1119fVXsLIeQzzzyTyvxN165bEmBoSMVd73WUCCEb01JKKe+55x75rW99SwJyZGRETkxMyDNnzkgTnD4Age28bRvhiDK3JDqb5Ca1axS7R51LkvaNtp61WrNGOeKuYz30kVLWVac4fl+L+dZ6rqGJGDt27GDmzJmuQjzyyCNcddVVdHR0MDo6yowZMzh9+jTr168vK+Zy3333lbQVQjBnzhyuvPLKuhV+iYPOzk7uvffesvmNjo6yevXqxDrrciGaXU+dOsX69euZO3cuUG7PlpYWWltbjTntprkIJ/ffVG/Br723ToVp/EKhwKpVq1i0aFEi21QKk94tLS1FynPXds0K3S9aWlqYPXs2HR0dqdlc10kIQaFQqJm9TX6XyWS4/vrrqz6WjqCY4CYMVYLQALxly5aS1ytWrGB4eLgYONzc6n379pUVidHbrlmzhomJCb73ve9x0003Vax8teENimfOnCnqe+LECV566aXEVbp0uRDdrn19fdx4443GNq5+w8PlP3r7zWVgYCDW3Hfv3s369esDx79w4UIiuySBECIL3Imip/HV+9ChQyUfmEKIu4BvSCkvmiU3JvxsfuTIEbq6uhpKp/3799ekvoJpfQ8ePFiX2iUm/yoUCpw7d66YPVgJAveAs9nsyYsXL5Z8pAW1h9rXM6gVoujrtIuls0nuwoULy4JmRFtF0iuu7WO0jyyzmhDq1v1mVND9UdQzxl8G7o66ZsBOYDXwFRSNza5IC54iGu0aqtU1UsmYtZx/PewfeAc8Pj5eUhwgm82OCPX4li9cCnWHjjrw+0jadOteZDKZM0IV/AlEXJ3z+fywECKwYHI2m50UqlBN4jZevaKMGbd9FB2rvZ5CMWv/BM7dLipw3iSdZz3b29s/Hqa3q9fo6OgWIcQKR95XgItCiC8D90kpG7IcWKNdQ1H8xG1XrTHDbFDL+ce9jhKhgg3qM6j00FOoLBxj2iOwCJV99iVgj/Ne7BTJWh6otOCzeLJodB2BG505f6GCcT6ByjmfwMnE846D+kB8FXgL8JSPHh9ApVQ/APxkkD1RmUE/4bZx5vhkkP1R2WvvAiaBNoOOm4HnUMksf1nt9UTVMXgfiur8OKqOxM14UqdD+uv2KtPN8dfbUCnSJ4D/At4LdKTtiwZdz6Du1otzQRWlupTmdeTY778df/p/Qfauwlgf5/KP+4scv95W6/k7viiB9+jzA54FRioeo0IFWxwF3xzQ5q9p8F+hUVl4/xyh3Z8Bj1YwjgR+P+D8e502a52/8wxtRlA5698GjoaMt1p7PRtYEND+SmfcVQFt/tUJCn9QrXUFMiiW2686sh9Epb3XvPYDKgX+Lai6HKeBf0DVFGhL2y8d/b7P8KEyA5VlmKZejwEn6jRWC5DzvM7XadxWx89bDeeuAn6p0jEqzoQTQvwCcI+U8rzP+ZWoegBfqWigKQAhxAeBv5NSnvU53wm8Hbgb+AjwF1JbICHE24HnUXfLq6SUD1VRP4Fiw/1zfVxPm5tQd9NPA++UUn62grFuQN1tvwNV+exLwP1SypEkMiuFEGIe8GMopt1eVBW9LwPf9bPHdIUQ4nZUIPyPtHVpZjREKrLF9IEQ4oeBjagf03KooHuflPKVVBXTIIRYzeX951eBZ4DPSymfTFUxi6mFKLfJldSRTaMGbZyxk44ftbZvpX2quTZhbXO5XGxbxV1f573HUHuIkfZ10zxQX39fg9qP/motfLtRfKlWfldlmZeqOW7asS0RJVFvby8HDhwwts3lcmXP54WNUcPHl2TE+cUeP8rjMfl8flhP5Q6yo8l2+nuV2DfKOuqyouiY1vqmjWo9ppTkUat6P55lKktQ7XVP43HIStawGusfmZJoz549xToFBw4cQEpZliEyPj7Otm3bSs5t3bqVp59+OrCGQC1hokAfGhri9OnTLF68mFWrViWW7aWY98pdsED5aaFQWHDPPfcUbbRx48aSProdt27dWmbXjRs3osvQ+3jXxlS/wotdu3YV8+pN4+s03mE6un1M9UFeffVVxsfHK1q/Rke1fDtoDf3gXUu3RkGt7F0oFBYEXdd6jYSk17XuS67cY8eOFRN+dFt5a9EkGddvzKGhoVB5fn1PnjxZzDwNQuQAvGbNGu6++26uueYawD8DST8HymCnTp0qocMeGxsrZljVEiYK9BkzZpDP58lmsxXJ1inmW1rUY7LeDCw9A87bB8ptZcqa0zOP9D5PP/10Ce12Pp9nfHzcmKL83HPPcfz4cd/xdRrvMB0Bdu/ezbp169i/fz+tra3FlPOurq7U0mXrBd23W1paEELEpno3reHk5GSgj3rX0h17fHycFStWVDotI6Jc125KclKYrlc35b63txcot5UQglwul/hmSvffGTNmkMlkuOqqqxLpG+fDN3IAfvLJJ+nq6ioaX0+l9UI/t2rVquKnFFxOXezr62Pz5s1RVUgEnZbam15caQqtaV6FQoFXXrn8e9Jb3/rWkj5eXaDcVia7hrXxs+/evXvL7Ku31WXp9ooy/oYNGxgeHqarq4tLly6VpD2bPgSmEvxsPzIywpw5cyqW495RmuDn1+43sGojqt+9/PLLiUsN+F2vw8PDLFu2LHDckZGRRPVadP9dvnw5hUKBPXv2sHXr1kT6Pv/885E+iBLtAQshePTRR8vYRo8dO8amTZsYGBgovu9+ZQ6RPyX3gIFAWwghys7rdt24cWNZm6T2DVvHLVu2lMkK09HUx2/8wEZNiOm0ByyEkLW+ru0ecAC89M5Llixh+/btxna5XK74VcGFTol98uRJurq6ak5pbxr73LlzDA8Ps3DhQo4dOxbpa0ZU2f39/cyYMYPFixcDKk2xt7d3gV+fnp6eElvlcrkyu+r2jGLf/v5+Vq5cSX9/P9u2bfNt29PTUzaeTuMdRUcT9fe+ffvo6uoyFgqaSjDRva9du5a9e/fGqpYV5ktR+oyMjJDJZGpi8zBfdm/A5s6dS6FQCNy7DoLJlwYHB+ns7CwW+tHHPXv2LGfPnqW7uztRgRyT7RcvXsyRI0fKrp8o+p49exYhRLTCRM3wqEbSI5/Pnw0bO+n4jfLoULM9hjaVDvsYWnM/hgZszOVyieVVwwaxjI56gH4MmAu8O2bfq4GLTt/3xOmb5EBlMkkCUja5nFf+/grGuRLFyPrXwNMxbPFDqJz+B6o0308Ay5z/bwd+M6Dtn6LqOdyGDzs0ik7+x4BfAFoijJ8FzgPXA79Q6/VtpAP4fmfui1HZgUnl/A2ww5G3KWKfNcBdwCPAQynMXTg+cheqrkbFz3ajUtPPoeqvXDD5KKqmyiuOv70u4TjfAo4HnH8GOBhBTtbRdzMwCtweVYfIWxAOuoCTUqWKxmWmnY+qY3BKSvnFmH1jQ0o5IISYL6U8GdDmqFNp6UwF4xwD/k4I0YUqEBKlz4vAi0KIO1EfFBVDSvmLnv93AjsDaoLOAg5JKZ8IENkK7JdSfjWiCm2oAj4HpZSfiqr3FMF8VF2EI6haEklxBcp+/xm1g5SyD+gTQrweVW6zrnD861NCiKtRPiNQNzWVoNWRMYAK6qbCx7NRtVC+U8E423yuDwCklJtFlGfJLut7AJWwE/mXZ5uKPIUREIAtLCwaADVjRa5m31rKiiszCUtrNZld4zAYA5NB56s5z0Zj8K0nqjX3CDZPlZm6kViow3TJ5/NV07OWvh3rDliIdB/ZqIWsuDIBgtqZxg2THUfXGHOv6DzEm2ct1qRZUK25R/STisdJiijzrLUOUXWppq1q6duBe8Cm/O+dO3eW0DTr6ZdhfXXqdW8aYRyY0l/7+vrIZrOJyTP90pYLhUJJZos3ndhEMe/cfQKXK+bH7TM6Our7DJM3BVWn6XYfm/G2MY3nXYtbbrml7LyuczabZWBggEwmw8WLF8nlciU6+9lveHiYTCbDjBkz/A3fZIhyXeipuVHlmGwOFLMs9XEq9aW40NfYNH5cHUx2iFIDxS8N2E3H9jt/5syZ2Hxy3nXZsmULg4OlJCqm68ELPxsE3gG7kd+b/z0yMkJHRwevvvpqkeFX64P0PPSfpG+wKZRe1ZIVVybAxMREsY37SWuqi7F169bEffx0F0JIryyfNoHj6Wsxe/bsMn02btxI0DhhMquxJo2Kavm2EELqdT7CbK6PU4kvJZl33PH95q7LNflfWA2UIJubbGWyZ9R4E3b96vpGtUHFtPRB1ORhfYVITlPvRxftUrknQVS6bS9Ntj5Pbzris88+G7vP3r17Q/XUabrdIL969eqiHfXxHnzwQZYvX25cC5M+fuO466X38VsTIQTZbLYuFOL1RJTrYnR0lNWrVwfWw9DrfJgo2KWUxW9guo11Xby+tGvXrqrPO874e/fuZe3atZHkJqmB4udvfrZyg6KUMrY/hl2/Jn3XrFnD4cOHOXfunK/cimnpg6jJo/Y11SwIgx9d9KlTp2Ll4EfR7+DBgyUfEHo7v7oY3qycMFr6aui5d+/eIoW9Pp5ekyLKHEzjFAoFXnzxRWMfvwtx3759oftxzYaovn3s2LHA2gxR5bj1RUwXfhT/qyai+n8cJKmB4udvzz//fOD5I0eO0N7eHku/KHNOYodQllshBO4BcOnSJTZv3kxrayuzZ89mYmKC/v5+zp49y+HDhxP1Xbp0Kd/+9rdjKW6SNTAwQG9vL48//nhcOwDQ09PDwoULmT17NitWrCjejZ4+fbpkf9vbrqurC+889cPdA/bqGrVPVD1PnTrFxMQE4+PjtLWpz9Sg8XT7LVmypEwHP3uMjIywbNkyd88rdH3dlOQnngh65Li54DD1BtpqYGCAmTNnMjY2ZtwjjSqnv7+fI0eOkM/ngXIbV+pLcfHYY4+V6NjT0xM4fhQd9FghhCCTyQS+NtliYmKCs2fPkslkfM/v27ePycnJ2P4YNmddv8g2kDEyRxolJTnFNMihCOm8w65MHDLFJH0q1DMwvTLsfC6XG3YcJrJ9p3lKcqCtos49gs1D02bj+FKCeUZimKmGDpQycXfqr8NslSStvpJ563PW9fWdZ9LFAF4CfgQYJkb6IbAfRUwJKoWxUIlTAH8FfB34NwLYmWPIuxI4ieIDezig3f9yxn4R+B8RZX8O+CVUmm+kVNMAWXcAj6LYfD/j0+YRZx4jQJfh/BJU5s5bgH/ykfEJR843gbsi6vb3KGr5E8DyStekmQ5gEEWsejTOdaHJ6HVs99PA3/u0+TSKuPUocFOd59jrBJ75zutjwKdTsvcsFGff64DHfdr8rnOtPAj8eAVjXe9cu78IfLYq+idUZKWzAL4U5yksxFHghSrK+1FnjsaLCFXXwhi0AmRK4GNV0u9ZVFq433k3JfRtAW3+2mnzJuevb80H54P2+Rjz/Lm0fSKtA2h3bGCssxFDzs8CMsDGf5z2XNM+gN9wbHGj83dGQNuXgMEqjPn7fusSW1ZCBQRwR9rG13RaCayrojwB3BlwfgswO6bM1wOZKum3BlgT0ubOoLswVGGk28Pm6rHv1RF1e2NQMJ8OB+obSkWFaVC/0bzR59zrgGza80z7AGYC253/w3x4KbCxCmNmCCjyFeewtSAsLCwsUkKsWhAu4tQj8DuS5GqnWQMibr+0a0KkZd/pVBOijjUgaupLlXKOUigAACAASURBVMyvmjUXqoF61pypyryi3CabfgUMQ1ibGDK8t/5lbZYtW1bRr526TD95pl9Vw3SPazd9vjLGGpj0DrNVlDmF2df0y3wYgubZTEdCe5X5YpS1TOJ/tZifzzg118U99OugGj5cybpEjTN+R6R6wCZKar+8/9HRUQqFAlCe197X10culyvK9avn4G2jQ++j06b7pAEGshQGUcW78m699day1Miw+YXR0mezWU6fPs3Q0FDxOc+gNdBleWnB/Sjmg2zlRzHvrTUQZl8hREsU33Bt4/rGVIG+ngcOHAhLSTX6YpgPmlJzTXUjCoVCqC/FQZTaLzt37iSfz/vWJ6kmTLEort/HWZc9e/YUa9dEuBZis6FGLsjuR1+u00e3tbXR63CI6bTt7sP7Ln20SUY+n6e1tdWXTVfvA6VptgsXLizJvnKdJAhBVPFuBg2UZ8OY5udN1YVgWnrXZvl8PhJ/mD6+lxY8yhqZ2vj18ZPrzSh67rnnIo3rXfsNGzaEzrOZoK8n4JuWvmnTJl85N998M3fffTfXXHMNYM54i+JLLi9ZtaD7g5vuO2PGDHp6ekraHD9+PBE1e1xE9eGwa3piYoLdu3cH+uTTTz/NokWLQuU888wzieYSOQCH0Ze7ihw9ejQSfTSoXO24dNwm2nQ9zRbipWGGUbX72cBPd2/mk65bEvrxqOPr5032DUvvjEJL78K1cVTfOHHiBLNnzw6dZzNBty8k88cnn3ySrq6uYhAx2VyXa7Lx4OBgIJFnXPitZX9/P9dee21gm6jU7HFRCx/2Q9TYkDTtOzItfUIq8sTnPW0Ca84KUUqbbmJd1uXoc/PKNMnr7+9n+/btsejg3TvvuH2C9AyjuK8FxbzJHgMDA7S2ttLT00N3d/e0pamP6o+Dg4O0tbWxePFiuru7y+Zu8kGvTd21qpYvVTI/n3GitKlaRbZq+PDg4CD5fJ4LFy74xogo6+LKamlp4ZZbbok/z2ptfOtHhHTX2Bvjph+iKk05zGQyJ6PI09/PZDKhY+r6RumTdA3CXlerT9g6VzMFtJEPoCWTyRQS2Kts7lF8MIn/VTpHXa9qXceVHHGvg0p0jBobPOeH486nGo74f4GfQ7GXtjvvefOgZzrnPgTc63nf2+YjwCdRab3X6+e18f4clXqYd9uh0oIngLkJ5/AkMOCR939QBJOheeyohIynUWyo3wzS3dPnfkf+Y8AbovQJkDXTscfTwBkf+/6qMycJ/HREHT/t2FUC1ybREfgg8LeOjF+rZJ6NdDg2vw94HJjpY/P1qLTVDxExIQO4FdiFIrz9+TB7Ae93bNsKLHT+/+Fa2Njxoc8F+RCqzMC7gCdNNklhnf4A+Jij82uT6gO8AfhP55q9v5rzqnSCLUABRUl9Fvigoc0vAqeBtzpBqswZgcMoqvQX8Ml997T9JeD3tPfmo3K9E2VfORfJHZ7XC4FPRez7deC/gXXA0oh9FgDXOYv6aIVr8MvAKccGxvoSwBHgj1GszZEy8VBB/ceBH6hAt33AZ1EfUu3VcNhGOFC1LiQwK6TdFqfdbRHlPuwE4M8A+yK07wE+4Hn9IQw1P6o050AfQtVJuAQsc/7Oa4B1OuXEi+83xZ0Ych5zrtWNVLn8Qlxaeh0SeBl4DtiBKiCi45hz7jtOWxNedCaZJ4QiXkr5fwzvnQC2R1Xa0P+T2ushVKGgKHgJVSNhT4zxhoFhIcQ3qZyWfhhVhOQEZvuDsu/jUsrHYsh9GdglpQyvEO+PF4H/klLuqEBGI+KngfdJKcuLYHsgpdwhhJiPKoYUBS+j/Om/ieAXUsqDwBc8rz8Z0LxSvAh8K8CHLgK7UXf9L6HuFtPGXtTd+NMVyukDDkgpv1sFnUpgU5EtLCwsUkKiVORaI0k6YTVTc+OMX4207EpSGmsxfpoptmmilrTrldi0GXys0dazWVKSG/IOWIj4NNBhfUSMx2XijB+jbaisQCH+fas+fhL7J9GtknnXAlHm7bSLrXclNm0GH6t0jGqjWj4cRVYl8461B5yEPtpEJx2ljSnN94orruD8+fNF6nUd3tRcv5RJl4rd2+bMmTNks9kSWaZ02oGBAd7ylrdw5MgR4DL1tknXWbNmIaUsZj9Vi5Y+CpX5DTfcUEIPFWYbP4p53VbuvGbOnGm0v0m3Xbt21SVFtVrwS6N2L0A/34sq25uyq/tBELW5Sa+hoSFOnz5dTD32S413Ke3jQF/LMDp6NwXfT38Ip6evFGE6u7T0AwMDgetYTz+OFYDdPGwv9E/esNdR+/ileF511VW++nlTc910yM7OziKTqZui6KYWum1mzpxZxpLql2p95MiRMl29aaQdHR1ks1nGx8dLUjG98zl48GDY3YpvTrm+BiZbHT58uExH3TYtLS1kMhnmz5/P2NhYWXuTrfL5PJOTk2UfVkG6Pffcc2UpqtlstmZpqpXCLz1eSsnq1aurItu1h+4Hfnex3vXw6iWEKAkkptT4QqEQmZnYC+9amsaPqrs2j9i1Eqqps8ucDhSzccPkuLJ0P9bLLiRFrC0IIYR8/PHHGR4epqurC1B3BN73wl67fR544IFAGY26BSGESKqrrwy4nJJ88uRJrrvuOt+vNPoamMYXQpTZN8w2ldo/qm5hMtJEvbcgTHY3+cXChQtj+1ilOgshpOtDfj4WRfeJiQnOnTvH2rVra77eYTob2vtu+dTLj2M/huYyjbqpeECRJdTvtalPmIwdO3YYF/PQoUPcdNNNRt38+gwODoa20Wsx+LWLo+vIyEgxF15v45Uxf/58RkZGOH/+fKQ8/rDxTfb103F4eLhsjcJs4PaJotuDDz5Y1v/gwYNl3zgaBX5zPnr0KOvXrw+s1BdXNgRfO65fBOnltaWpTaFQKNuOigqvP5h0131Gv85dluIzZ84k1qGaOnuv9bCiUFGv8aNHj1akb6wAnM/nh7dv3162B+y9DTe93r59O3H6QLkj7t27l97eXiYmJop7ujr0Pq7BxsfHAUWp3dvbW9Kmv7+fefPmlVUjMzlTf38/S5YsCdV1ZGQEIQRz5841tunp6Qn86hJE453P54d7e3tL1kDX1STfpGOhUGDBggXGNTLZytsnqm66DQcHBxkfH+fECb9HltOFad2HhoZYs2YNTz31VEVfOcPWyXQdBOnV399PPp8v2tLU5sKFCyVBMyr0tTTp7vUZkw+ZZMZWJAbCdHarJObz+UBaepMf69fPvn37yOVyxSppiREna6NeRxKK8wjU74HyvDLjjF8lmvjEufK1GL9aFPNhchqtJkQUevmkeldi02qscZI6BVJKgNtyuVygbI8OviSxKaxlVXy41n6cuqFCFv8K4HngzfhQThv63AE8g2Iu/ROfNo8A70Zl9/gy16IyYH7Z+f+Xgb0Bbbc48t4NPOLT5h9QGXa78CFbrMBWApVt+APAKxjSsoGPAl8E7gZ+M6LczwK/Dfw7CSm9nTnfj6px8LNp+1WAnhL4Bv5M2G49jYoIR4EHgHeisj57YvZ9EsVi/TyG9G5gEzAA/E/gbyrU835UOm8oAS+KcPYU8I9pr6Om11ngdz2vv0qENG8fWXc4165vbIktM20DRZz46xzHb43Q9t+BV0PaSOBnUAV87q+Sjvc78n4GkAHj/haqzsK/18hWS5xxFhvOnQCeQhWRORVRnnQC9hFgd0KdDgB70vajCHp+lIAaBqhU+d/1C9AJxpPAb8do3+b02R7Q5m/9/C+Bfk8BvxGj/a8A/532OtbQP0JjS9yjIRMxTBBCrJRS9kdoNxtF1308SBbqLnERcFZKeb4K+l0BdKBy4VeYdBVCrEAVqJkPjEspA+teVKCL0VZCiG4u14vokqqWQJis5agA2gG0SVVzIq4+rp1fjdt3KkMIsQw4LKWciNEn8DoQQrSjPkQO+bWxSIYosSW2zGYJwBYWFhZTDQ1VCyItWvRaULzXGs1E/94IutazNoBXVgrjBtaEiNKmXpT29RyrGutREz9Oe19F22ORXkSkkw6kRa8ixXeg3CQMFIa5RP41Nck8o4wfl/3EpLPpV+MwUKV9y6j2qkSHOLKi+I6fTaPY0SQrom6huldyRNGjnmMFrYdf23r4caX1gKuOKBTxGp10GS26LkOnCTdRzHvpp001IvTaCGEU735U4kkoy5PayjR+kD3d8ZP08aJQKCzQZQTVoqhXWnKUmh1REYeK3USTHsUPTBTsUfxQ92VvDQ+XkbweNTp0G7m1GNzn8l1d6jGWF14/cNu5iVheX/Szf9RxoqDhAnAUinidTlqnpdZl6HTupvfWrFlTUs9hdHS0pGaBXhvBNG4UKnHTuIcPH+bcuXOxbRWFylwfz8+ezz//fFGuLsOvz969/rXa9XH96nRceeWVseedFHqthHw+z8yZM5kzZ05sWX5U7EBZlt/u3btZt24d+/fvp7W1FfD3A71GgR/lepAfeqnU/Wp41Kq2QRQbjY2NVTX4wmUbFwoFWltbmTFjBqOjoyxdurQsWUL3g/HxcXK5nPFD2M/+uu1GR0cTFWpqqB/hRMwcbKdPSRsRoa5BWB8oTTW88cYbkVKWpCPqcnWZfuMEzUfEyCmPYqsk4wMV6yxEOZusyb5umuxtt91WlzoBfmvc39/PbbfdRjabjaRDkKwTJ06wfv16WltbkU5dEVMtlCg2Ndkxih/66TY8PMymTZsC2wwNDbF58+aK1yLIRm4qcCaTqcq6B401ODjI5s2bi2sbtnYbNmygpaXF1/5Bc7rhhhvizyfOfkWtD7Q9lgULFoTuAWez2dh7wCZG2SCYzuu6mfZK9XGqyWSbZJ5RxteZYJPobGLTDQPTaA84zK/j7AGbZEXULVT3So4oetRzrKD18GtbDz+umcMnOaLQYLvOiQ8raSaTGQmT4U3LBDrD+kRJY9Zl6jqi2JYDX8exVZRUS12nJONXQ+coa1LrtOQ4vlUN28dJVTf5TgXjhqYNm25aqr0W+Xz+RJgeVRwr8npU4gdRUtXjzqdmDp/0AJY7k1ntXPASRQEelxJdAh9wZAyiCA/DqNiXAweB3wP+zHRBAH8O/AaKyfmqsIumDvbqBM4BPwt82ft+2mtp0HWlsxavAC/XU09UqrYEPuodF5Vk8u0kegD/ChSc/1/vyO/wkwV8D5VJJytdJxTduku5/mZdljPfk8CPAjtN4wHvAP7RkfG5aq0H8D4UWexduq96/n89cBz4uSqu8Wngaef/z7h2Ns0JVebgAort+Hycubuxxfn/YCW+XHPHT2BEAfyw5/UNwPIEct6Mk7OPosq+KUKfzzlO8RFgzKfNGCrl8jjw+Qaw1+8A552LaZIqpcnWSNe7USzZV1Bn2nLHr+5Fo5IH3gj8akKZVwPXel7/SEDblc6FOwdYWoX5vIq6UVhqWnNU3YJJYK0zrikI7QX+DViIyvCqlq0l8PEI7X7VaVut1O7twHzn/6z+AaC1/QhQQD2IUJa2HzJO7NjidzTcUxBSzephz+tdCeV8zfP/AdSdThgeR901PALc6tPm/wFfQ11ILybRrcp4GlVg57+Af3bs16h4DBiSKiW5rmnJjl3ebXj/G6gCPElkvqi9fiig+QjwL6iU7NNJxtPwNeABKeWgz/n9qPok+1A1DC74yPhvKWW1k2BaovihlPLPhBB/Xi2flVI+6vl/HHWt+uE7wD1SpYEfiTlOkthiREM9BWFhYWExnZBaKnId0yqjyGiIlN2pjlqnJCdNf41AO16xH1Y7nb0aVOlxZdRy/WqQTlyNuFDz2JLaHbAQlVNtR2kTQ0bDcJNNVcRY87rSp4f1a0Q/jKhzoKy4Mmq5fnFkVyN2NMqaproH7EcBnsvlmD17NkBgirCbpRY3jdhtc8cdd5RQzOdyOcbGxor66a/93vOi3tTbYfrUQyc/mOi9TenAUkpaWlp4zWteU/GYfj51xRVXMDk5yY033mjsF5aaa9I7m83S2dnJmjVrytrotO2ublHTl3WE2TIKxb3JV7zzjpJWa7LvwMAAAC0tlX2hjiPblE48Pj7O+fPni5mI1VgPr4yZM2fy0ksvkc1mi1xxus7e1OYo9kg1AJtoowEKhUIxJVJPqxRCkMvlSlIZTW28VPNumuKpU6dobW1FCIEQwkgxH/Ta7z3tfN2ot6PoUw+d/GDS1ZQOXCgUWLlyZVXG9KOVBwLTnk2puWNjY0Uqem/ad0dHB9lsFiFEMfhCaYqribbdLzU3Si2MMFtGoYk3+bc+byEEc+bM8bWVnlYthKBQKLB27VpfrsCoMK2dcLIz9Q9O3Y9mzJjBqVOniiS4ehuTfUzpy4VCoSR9WV93KSXj4+PF+KPbo6WlhdbWVhYuXMiyZctC55xqAH7hhRfo6OhgxowZJTUGhoaGmDdvHqAKdrh3tFDKONzZ2QlglHHw4MHip/2GDRuK6YOXLl0qYTjW2U7DXpve8+pUD4TpqNOBpwldN7/1vHDB9CN9fAT5VBDjdJheTz75JF1dXUhZXkPDveh1Gfrc/XR75pln2Lx5c+jcvAzTUcaL4rumeRcKBV580fyAj9+1dOjQoeI1mxR+9tm3bx8XL14saavrvXz5cubNm0dfX18xWIfZR5/L8uXLmZiY4MiRI8UAHLTuQfYYHh6OFICn9R6wEIKBgYEia+rGjRt59NFH6e3t5dChQ2zZsqXktdvG22f+/PkMDg4ihKCnp4fu7u6a7icLIWSQzq5OLh14PXSKo+t02QMWQpT5UiVzD7Olabww3w1bj6m0B2y61qf9HrBLfe4NHP39/axcubK49+PXZsGCBcyaNQuAAwcOlJ3v6Ogofo3yk9Hd3V3c6oByam0T1XYQdTjUn3q7EejAg8bt1ei9TWsxODhIS0sL3d3dFY+p+8L+/ftZsWIFQ0NDzJ071/euJIkPnT17FiGE0Q912nY/GS5NetDdOZhtGTReVN/V5x22Fnr706dPs3TpUp599tmKt5F02QMDA8yYMYMLFy5w++23B7Z11+LkyZPFtrp99Ln7remxY8eKc/Ebx11zPxmFQiFapb84WRvVPKqV1x6Bcj2KjIaiR5+qRzWpwpPKN40RgXa8Yj+MUk8kztyrQZUeV0Yt16/a9TWqFBdqHltSvyillKBqNvwyKlOqLDccmI1KG1yDIpUsS5sEPo6inP40Tl67dr4FlR10EyoLqzfteU/XA9gDbPCs2xerKHs3Tj0Az3uLnQtiXUjfv3f0+Vtgo+H8DFRG2WpU/Y2coc1vojIpfxt4h+G8APqArajaBVdXON9PA58F/hr4voQyPoDKAv0o8HAEGz2rvfcCcHeV1u/rbgwAfhB4MqDt7cAh4E3AH/m0edBZk7DYcj2eWipam5rFlqo4fbUOZxI7De+7hU7mOX9XGNrsA3ai0i9HDOdnOX1XOX9/Nu352qOxDudC/HTA+Vsc35nr/L3O0GYP8N0AGTmn70bn769XqPOJsKAZQcZjqCJJvw9cSnsdYuj9V8BESJsJ4I8ixJbWABk1iy0NlYoshGgFkFJeMpzLSCkvun8N59tQxUckij7d1CZQhsX0RhS/iOqHUsrJpDLi6owKQokvZO9110zXhlDPqBmvdU8b19ahsSVARs1iS0MFYAsLC4vphLrXgmgEinKL+qBKNRZi1yNI2q8adO3VqNFQZRvHHi/uNZrkmq5jPYfA+acej1LYt5E6wijek1C+R+mjH/ZpiNqvtRdh5z1tIsuM0y+M0j3ML/3eCxujEj+MS5Wu28EkI2wOYXJrtY5RbKkjSSyphoyka5rKc8BRqLXDqNHDKNej0MTrqaAipZTdqYywWgNJaL6T0p3r/XR6+I0bN5boa/LLKH6oy9B97tZbby17z01hnT9/Pvrzvl4UCoUF+nimGgpuTYOoMqLIHBgYoFAoFFO7ddvq7U+fPs2xY8dKMvG80OtruDpns1ljPQfTekRZ06A1rIYMv9gyPj7O1q1bAf/YkkoANlFrP/jggyxfvtz9dAylUw9rE7WPHx24RXVgqrHgBhrwpy4PqkeQlBpcz/2Hcn/w6gvJfEqXoZ83vedNYQ2D3tdUj0BKGVhjQpcRJtO7Jm4JAJNtve2FEFx77bXG9mCu5zA2NsbVV19tbKPb3zuud0319QlaQz8Z1Ywt586d812Huv8IJ0Q4TbdIUBQnSR+DbkhblrJqMK21N9DccMMNvjTfJ0+eZMOGDcZ02CCZ11xzjVsJLLRfGKV7mF+a3guT4SfHcN43JTloPK893CJHuiyTjKgy+/v7ec1rXkNra2tRbtCa6FTvXh2iUMk/8MADkdfLr03cuVYjHunwXVPTvkQtDwx7LmEU70ko36P00Q+7B1z7tfYi7LynTWSZcfqFUbpH2QM2+VSQjEr9MC5Vum4Hk4xm2QMOWy9TmyhxoRoykq5p3S/KpDTdhNCjh72OIqPetpjqRxgFeJJUzlqlG0M0uvYwH8pkMiOVyohp49DxwmTo48dNOU5C9R6lT4T1CPUfPZYkmWuYDJMNo65pqhco8GXgF5yJ9iZxQHs0/oFKFf0XFCuxm2baqbX5BvAWYBQn1dzPF4BPojKccm471COVZxw5gT4EHEalub7gec97wbwZ+GfgS8AHg3QJGGMliqzxN4BPJZERY6zrnWtovmMLiaJlTzweKq1WAt3Oazf776MB69KGSsX9PFCIMmcus0V/FCcl3eAbH0MxQEscxnRtvQSK9PQP8WTyJVizbzm+eo7LrMc1jUd1uQB9Jiscg76TgDRAezT/gaoV8F0U2/VJw/kZji+4qb4fDJH3WuCdhvdfD/xYSN+tzhiLnL+rDG32oFhzvwacSDjne4GzwIcBWWP7CmCt53UPMLNCmRngB7X3tgBdAX1+yp1rnGsaaHX7QjlFPXAR+As/mcAPuX2TxhLPB9c1blyq5Zq5R2rlKKWUUgjxaeDr0pAeaDGl8Fco6u9jqOCpYxT4AvAM6m7nm0HCpJTG81LKf4ugy/dQhWuGgM+haiDo+EvUXfIJ4PsiyDThXuDbqPoBPQllRIIT8fZ6Xh8MaB5V5kXgn7T3doR0exRVd4E417RUKdAPAZvc6K3hz4AvBMh8BvgLp2/SWHIGuBtlxz9F1X6oOWwqsoWFhUVKaHRaepuSPA2RNN04St9m9qlqpO9WkkZcpdTy2OnetUhpbxQ0AyWRfS53miGKbzjtyvwjrG8z+1SMayZKm+IzvFHbR7RtRfpVsKZRxm24da/bHrCJVtuPQry9vZ3JSd9qfhYNDn2tdTp0Ez266T0TbXhfXx+zZs0qpqqaUCldu0kXL/L5/PDo6OjCOHOOKicMehq/1yYuVfqePXt8z5vStINSmfVsOm+adTWo3k0y8vm81G1XDYp5L0zxKMm6V4q6BeBCobBAzxAy0VDncjmklEU6cIvmg2mtg14DJe+97W1vA8pTRN0U2zD+NJ2OPM7Yfm20DL6yvP6wOesyNm3alKj2iJ7GPzo6Sj6fZ3Jykmw2WxzHS6WezWZLqNR1mNKI29rauOqqq8raetOsTbbV10wIddN59dVX09HREbo+7nroGXBha+qX0p7NZo0p2fp6mcb1sp2vX7++JrVi6rYF4Zf+6Eep7pdGadH48Ftrv9f6e2G+4Zfe6o5djXTiSr8m1+JrsTuGn12SpHfr9vK21+0cxbZBstavX09ra2vsVG1dbpxxh4aGuOGGGyIxPCdZ90pR18fQvAyiLrZs2VJPFSzqBC+brOm1zibrbePCzzeWLFkSOLbeT/e7oLFNr1224M7OziIbbpQ5V8yYG3F+Lly7xLVbnPZ6W33OUWQFyXCLNIXJ1dc0ia+E+YG77vl8vqL1CkLd7oBNey6PPvpomYN6Kee7u7vtHXATohp7wCbfOHfuHO3t7Zw/f56ZM2fS29trvBMdGBgo9rvrrrvK9oDDxm7UPWAhhDTZxRvUu7u7jbbzBhLvdaXby70GOzo6inTw3h/hgmwLoMvat28fXV1dRbp4IQRhMky2C+vjZ5fR0VEWLFhQFksaZQ84tacgTAbQUYsJWzQ+ovgGRAuEUfo0CyJeM5OFQiHw8VKvDeJchxFsG2XswDYJ1zTWnBsJDZGIIYR4FPgv1JbI56SUh9PVyKJRIIT4C+Ba4CvAoJTyPyL2uxuVXvpfwHeklE/UTsv6QwjxNIoq/SdRNRQ+YWjzCeD/ojLUFkgpjVXuhSL2/CZwh5TyghDiY8ARKeVnfdo/BBxFZfgNSCk/pJ2fgcoi3Ah8QEr5KwYZvw9sR9VfuFVK+QMR5nwfKk24DVVr4j3a+RwwjKKr/w4qzfxAmNw0kVoihoYNwAUp5W/Z4Guh4SZUYZQvRg2+Dm4EkFJ+eqoFXwfXoIrGtKFqaJRBSvmLwCFgDjDTT5CU8qKUcpuU8oLz+rf8gq+DTcA4qvaCqer7IqAdOGwKvg5uRtWAuIAK1FGwGZVqPInyCx0dwGzUh0ML6oO7odEQd8AWFhYW0xGNcgdsYWFhMe3QEAF4KufvWyRHLWtCTDW/inoN1aOuwnSzfSVIZQvC9KvmU089RU9PTzGNcHh4mAsXLiCE4JZbbrGPo00T6L6xY8cOY7p6Lpdj9uzZrF27FiEE+Xx+2JTqrveTUjJnzhyuu+66hq0PYEKUx9y88zWl65ra6WzEmzZtYseOHSVpvaZ07rDH9vR1C5OhI5/PD4PKWIszbhqPklWCVAKwEELqtM8TExO8+uqrxXRFrX3TXCgWlcHrG1u3bmVkZISOjg5f33D6AJRRiQf5lNuvWfzKdM0EzdfN6vJSp4+OjnLrrbeGXmu6zYUQZWOF0bZHkWHSTwjBzTff7Lum+jg6Ffytt94aRg/fUGueWkF2ndL5vvvuK1uIIGpyi6kLl94bKFKaP/TQQ8YL1dTPvanQfaqlpYVCocCqVauKNOfNhDAadO98oZw6fc2aNWXtXFsCLF26FIBHHnmk5LxprDDa9s7OzpLgGtbH1W9iYoLnn3++OOewBy4t7QAAC39JREFUcfTzup28MtevX1+9xagSUrsDjprLffLkSa677rqG+tSyqB28vhFWE2Lfvn3cdNNN5PN5gMj1AQqFAitWrGi4u6EgRKmvEVZjwW1nKjjjrfuQBtW7SU8oX9O4dT1MchtpzVMJwNls9uTFixfnet9rJqNZ1A66b0TxTyEEmUxmJI5Puf2axa90u2QyGS5evFjSxjvf3t5eDhww5yBEuNZK3lu4cGHxG4lpbNO+a5iMsL3aXC53fHJysjVoziYZJrt40Wh7wKlsQYyPj8/zvs5msyNCiE6/9u6GvMXUh9c3nF/TE6Ukh/mU2y+5pvWFfs0IITqllKfc//P5/F4hhO9+XS6XOz42NrYmk8n0CyHm+rXLZrOTQojAp6NaWlqOSSkXuGOPjY2h6fJihHUrkSGlPKXPyf3fb876uCYZQEmb0dHREplpo6ESMYQQPwncicp0eVRK+QXTQlhMPwgh1qJIIvcCc6WUtzrvB/qHEOJGFNniWWBUSvmGqexTQoilKDLQj6JYjd/uvF8yZ6FStW9HkY9+Ukr5iKHNAIqg9E+llPkkdhNCfB2VDn0v0COlPD2V7R8XjRaAj6JSJy8A66WUvp/UFtMLQoivAm+WUuZj9vt34EYp5ZzaaNZYEEJ8Hng/8B7gHlQat+9FLoToByaklGu1929AsQ3PklKeT6hLG4pS/g3AvwIfl1L+VhJZUxWpPQXhg58FXkEt2oaUdbFoLHwcuC9Bv/+NqhEwXfCXqMI6XwPmBAVfB+8ETDc6zwEfThp8AaSUE0KIjzj6vAtVeMfCg4a6A7awsLCYTmiIVGQLizAkTW+1abEKcdP9rd3qg1TvgOOyCDTaIyQWtYMpXT3KY2WmlOSp9DiajjjXUNBjalEeJdOh261RWCaaCakG4LD0Sjd7qbW1lfnz5xspaCymJtzEA2/aqam2w8yZM5k1axarVq0qeXg/rN8VV1zB+fPn2bZtW1MHYJOd/FKQvXZYunRpmZ3016Y6HF6q9+3btxuJLr1j+13To6OjTW/7aiD1H+HCUhy9jK8W0wt62qmXmtylYz937lwZ8WJYv1wux8yZM0Pp7ZsF+nz9UpC9dgjrBxSp3r22a2lpYWxsjNWrV4fq4pcy7V7Tu3btqp1RmgSp3wHHTU+czp+W0wlx0tUHBwfZvHkz2WwWiJ6SfPToUTZv3tzUfhX1GtJTkKOkF0ehmDfdAevj2mvaH6nfAVeDDtxiaiIJ5Xkl/ZoV+nx1unWX6v2tb31r5H5QW6r3tra2KfMNpBLYH+EsGhKmH3RM9OkLFiwooTw3/QjnR1l+9uxZuru7yyjLmwlxrqEgandTP5PdBgYGmDdvHidPnmTLli32R7gKYZ8DtmgKtLe3nywUCoGZkUkozf36TTVEoHYvsYG1W31gnwO2aAoUCoW/BPqllMJ7APNRqetXm4LB6OjoQqfdjwCngV7g7V4Z0yGIOHP8UeB9jj1yqFTlVpMNPHZrQ9XR2AZ8CJXaPG3sVmvYO2CLaQEhxHuBX9NrHlgEQwiRAU4A10gpD6Wtz1SDDcAWFhYWKcFuQVg0DJKyY0dMm62Y7bdZUA17eG1hWctrB3sHbNEwMD1Hqp03Pq0Q1s/TN0qbpnwawotq2MNri6TrYhGO1J8DtrDwYteuXUU6dD31NQg7d+4MpEE3tXHTktvb24vPyk4V7Ny5s4Ra3mRLk63vvPNOjhw5AqjA68p74oknSuw2MDBAoVAo8vFZJIO9A7ZoGAghZBhlut8dsIkGXa9tEEZxP1Xu5Ez2MLQx0tPrdjNR3ptkTQW7pQF7B2zRUDBRyY+OjrJ2bfDDCyYa9DCqdJeSPZvNcv3119d8bvWETi0vhGDOnDlceeWVdHYqqjw/enpTPQdTW1eeRXLYAGzRUDAVbikUCrzyyiuB/UxBQ0+lNRWpmZiYYGho6v2G5FcA5+DBg8UAbGoD5hRkk91OnDjB7Nmz6zSjqQkbgC0aCj09PQghiqmvL730EtlslmXLlgX2u3TpEps3by6mzXZ1dRXv6PzaTExMcPbsWYQQHD58uJbTqjv85jo2Nlacq27rkZERFi9eXGY3oEzWvn37yGazHD16tN5Tm1Kwe8AWDYO46bJR+zl9JwuFQuBjl1MltbYa9vDaor29fbhQKPjuNUwVu6UBG4AtGg5CiL8ETgI/A7xLSvlYjL5/DBSAdwMflFJ+QzsvgBHgTuDvpJRXVU3xBoMz12PAm4CvSimXGtq8E3gH0A+MSCn/IEDe3wLfAT6ASmn+dk0Un0awiRgWjYgPA0uklEvjBF8Hvw4slVIu14OvgzuBOcDLwHIhxLUV6trI2I6qlfES0COE2Gxo80fAemAl8Hsh8t6Lst0a4Perp+b0hd0DtmhEvBbYmbDvDwBPBZz/F+AOKeUJIcSdwAsJx2kGPIqa60lnriYKijcBZ4BTwHUh8t4A/CfwCKqwkUWFsFsQFhYWFinBbkFYNBwqqT1g6xZYNBNsALZIHXrQLBQKC6SU+B3eX/jD+uqPr0kpF0zVojy6LfL5fNnc9PdMbZK0bWa7pQm7B2yROgqFwgIvdfnGjRvLag/09fUhpSyrPWDq661xcODAAfTzJtr28fFxtm7dCoAQIvARrkaF++ETRFGv08QH2WPbtm1lbXWKeW9G3Ny5c5vSbmnCBmCLhoCexWaioC8UCixdWvYkVVnf5557juPHjxfp1/WML7+MuL1794amPDc6wijqIbo9oNy2QRl2FvFhf4SzSB16uUMRQIleKBRYuXKlb6lEvW8Y/bqPPk1ZXMZkizCa+CB7xGnrOd90dksT9g7YoiEQlUo+SV+dbt1E2z44OEhnZyezZs2q0ozSQdhcodxefrTxUdqePXuW8+fPW4r5hLB3wBapQ0+dzWQyXLx40be9liYb2FenRQ+jSdflNxOiUNTHsUdc2zWr3dKEDcAWDQshxI8A70Nlr31RSvleIUSnlPJUSL83AV8D2oErUKSSPwPcH9bXwqKesFsQFo2MjwLHgc3AAEDEAPok8CEpZQEoCCE+AHzDBl+LRoO9A7ZoWAgh7gW+K6X8q7R1sbCoBWwAtrCwsEgJNhPOomFRJXr1yPTrFhb1hr0DtmhY6M+1+rSJ8mxq2Hn77KpFKrA/wlk0DExMDqaU5FwuB8DNN9/s28ZLNR9ER29hkSZsALZoGLi1DFwIIYwpyaOjo2zbtq3YztSmpaWFlha1w7Zu3Toefvjhkja5XI4bb7yx7nO0sPDCbkFYNAyEEDIojdinj92CsGha2Dtgi4aCl6kXVKEYU02IoaEhbrjhBgAefPDBsvPDw8Ns2rQpUMbIyEi9p2dhUQIbgC0aBvl8fri3t7dkD1inTt+3bx9tbW0ltQfCqOb9KNozmUx9J2hhocFuQVg0LKpErx54PpfLHQsbw8KiVrDPAVs0LEZHRxc6+7NvA3YAvwbcI6UU7jE6OtrqtPkm8GOolOUbDOdXoujo3wg85Z63wdciTdgAbNEM+AhwDXAl8FP6SSGEQDEpA/QCP2+Q8X5gLjAG3CKEsNtvFqnDbkFYNDyEEJ2AQFGn90op9xvaXCWl3CeEWAKMSClHtfMZYLGU8oDbti7KW1gEwAZgCwsLi5RgtyAsLCwsUoINwBYNhzB69SR062GU6rYwj0UasFsQFg0HtwiPl149jEo9jG7dRNFuoKO3WXEWdYX9JdiiIaHTq4dRqYe1MfWZSnT0Fs0Jewds0XAIo1dPQrc+lenoLZoX9g7YouGQyWRGhBBz3de5XA71qK/5tdOn5D39tamPjnw+P1yx8hYWMWDvgC0aHl4mZPd//T24TNgZ5bVJhiXttKg3bAC2sLCwSAn2MTQLCwuLlGADsIWFhUVKsAHYwsLCIiXYAGxhYWGREmwAtrCwsEgJNgBbWFhYpAQbgC0sLCxSgg3AFhYWFinh/wOYAMD4MzU52gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(decision_tree.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the resulting decision tree model using your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "decision_tree_output = decision_tree.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "decision_tree_accuracy = accuracy_score(decision_tree_output, y_test)\n",
    "\n",
    "print(decision_tree_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of a single train/test split, use K-Fold cross validation to get a better measure of your model's accuracy (K=10). Hint: use model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7397590361445783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "decision_tree_cross_val_score = cross_val_score(decision_tree, X_data_fitted, y_data, cv=10)\n",
    "\n",
    "print(decision_tree_cross_val_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a RandomForestClassifier instead. Does it perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "\n",
    "randomForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7403846153846154\n",
      "0.76144578313253\n"
     ]
    }
   ],
   "source": [
    "randomForest_output = randomForest.predict(X_test)\n",
    "\n",
    "randomForest_accuracy = accuracy_score(randomForest_output, y_test)\n",
    "print(randomForest_accuracy)\n",
    "\n",
    "#Now for cross-validation\n",
    "\n",
    "rf_cross_val_score = cross_val_score(randomForest, X_data_fitted, y_data, cv=10)\n",
    "\n",
    "print(rf_cross_val_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "Next try using svm.SVC with a linear kernel. How does it compare to the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_classifier = SVC()\n",
    "\n",
    "svc_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_output = svc_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "svc_accuracy = accuracy_score(svc_output, y_test)\n",
    "\n",
    "print(svc_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damn, that's pretty good, but it looks like it's because I forgot to specify a linear kernel! sklearn method defaults to an RBF one. Let's see how a linear kernel fares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "svc_classifier_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "svc_classifier_linear.fit(X_train, y_train)\n",
    "\n",
    "svc_linear_output = svc_classifier_linear.predict(X_test)\n",
    "\n",
    "svc_accuracy_LINEAR = accuracy_score(svc_linear_output, y_test)\n",
    "\n",
    "print(svc_accuracy_LINEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying multiple kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>accuracy score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.822115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  accuracy score\n",
       "1      rbf        0.846154\n",
       "2   linear        0.846154\n",
       "3     poly        0.822115\n",
       "4  sigmoid        0.769231"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels = [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]\n",
    "\n",
    "accuracy_scores =[]\n",
    "\n",
    "for x in range(len(kernels)):\n",
    "        classifier = SVC(kernel=kernels[x])\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier_output = classifier.predict(X_test)\n",
    "        classifier_accuracy = accuracy_score(classifier_output, y_test)\n",
    "        accuracy_scores.append(classifier_accuracy)\n",
    "        \n",
    "#Combine both together\n",
    "\n",
    "accuracy_scores = pd.DataFrame(kernels, accuracy_scores)\n",
    "\n",
    "accuracy_scores[\"accuracy score\"] = accuracy_scores.index\n",
    "\n",
    "accuracy_scores.index=[1,2,3,4]\n",
    "\n",
    "#accuracy_scores.rename(columns={0: \"Kernel\"})\n",
    "\n",
    "accuracy_scores\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "How about K-Nearest-Neighbors? Hint: use neighbors.KNeighborsClassifier - it's a lot easier than implementing KNN from scratch like we did earlier in the course. Start with a K of 10. K is an example of a hyperparameter - a parameter on the model itself which may need to be tuned for best results on your particular data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "KNN_classifier.fit(X_train, y_train)\n",
    "KNN_output = KNN_classifier.predict(X_test)\n",
    "\n",
    "KNN_accuracy = accuracy_score(KNN_output, y_test)\n",
    "\n",
    "print(KNN_accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing K is tricky, so we can't discard KNN until we've tried different values of K. Write a for loop to run KNN with K values ranging from 1 to 50 and see if K makes a substantial difference. Make a note of the best performance you could get out of KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6826923076923077, 0.6682692307692307, 0.7980769230769231, 0.7596153846153846, 0.7788461538461539, 0.7836538461538461, 0.7836538461538461, 0.7932692307692307, 0.8173076923076923, 0.7980769230769231, 0.8221153846153846, 0.8125, 0.8221153846153846, 0.8028846153846154, 0.8269230769230769, 0.8173076923076923, 0.8365384615384616, 0.8269230769230769, 0.8317307692307693, 0.8173076923076923, 0.8365384615384616, 0.8413461538461539, 0.8365384615384616, 0.8365384615384616, 0.8317307692307693, 0.8413461538461539, 0.8365384615384616, 0.8413461538461539, 0.8413461538461539, 0.8413461538461539, 0.8317307692307693, 0.8317307692307693, 0.8317307692307693, 0.8317307692307693, 0.8317307692307693, 0.8269230769230769, 0.8269230769230769, 0.8317307692307693, 0.8269230769230769, 0.8365384615384616, 0.8413461538461539, 0.8317307692307693, 0.8461538461538461, 0.8365384615384616, 0.8365384615384616, 0.8413461538461539, 0.8461538461538461, 0.8413461538461539, 0.8509615384615384, 0.8557692307692307]\n"
     ]
    }
   ],
   "source": [
    "KNN_accuracies = []\n",
    "\n",
    "for k in np.arange(1,51):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=k)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    KNN_output = KNN.predict(X_test)\n",
    "    KNN_accuracy = accuracy_score(KNN_output, y_test)\n",
    "    KNN_accuracies.append(KNN_accuracy)\n",
    "    \n",
    "print(KNN_accuracies)\n",
    "\n",
    "KNN_accuracies = pd.DataFrame(KNN_accuracies, index=np.arange(1,51))\n",
    "\n",
    "KNN_accuracies[\"k\"] = KNN_accuracies.index\n",
    "\n",
    "KNN_accuracies = KNN_accuracies[[\"k\", 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.682692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.668269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.798077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.759615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.778846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  accuracy\n",
       "1  1  0.682692\n",
       "2  2  0.668269\n",
       "3  3  0.798077\n",
       "4  4  0.759615\n",
       "5  5  0.778846"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_accuracies[\"accuracy\"] = KNN_accuracies[0]\n",
    "KNN_accuracies = KNN_accuracies[[\"k\", \"accuracy\"]]\n",
    "KNN_accuracies.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot this out\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(KNN_accuracies[\"k\"], KNN_accuracies[\"accuracy\"])\n",
    "plt.xlim(0,50)\n",
    "plt.ylim(0.5,1)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Now try naive_bayes.MultinomialNB. How does its accuracy stack up? Hint: you'll need to use MinMaxScaler to get the features in the range MultinomialNB requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_train_NB = scaler.fit_transform(X_train)\n",
    "X_test_NB = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(X_train_NB, y_train)\n",
    "NB_output = NB_classifier.predict(X_test_NB)\n",
    "\n",
    "NB_accuracy = accuracy_score(NB_output, y_test)\n",
    "\n",
    "print(NB_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting SVM\n",
    "\n",
    "svm.SVC may perform differently with different kernels. The choice of kernel is an example of a \"hyperparamter.\" Try the rbf, sigmoid, and poly kernels and see what the best-performing kernel is. Do we have a new winner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We've tried all these fancy techniques, but fundamentally this is just a binary classification problem. Try Logisitic Regression, which is a simple way to tackling this sort of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8269230769230769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg_output = log_reg.predict(X_test)\n",
    "\n",
    "log_reg_accuracy = accuracy_score(log_reg_output, y_test)\n",
    "\n",
    "print(log_reg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "As a bonus challenge, let's see if an artificial neural network can do even better. You can use Keras to set up a neural network with 1 binary output neuron and see how it performs. Don't be afraid to run a large number of epochs to train the model if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 200)               1000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "NN = Sequential()\n",
    "\n",
    "NN.add(Dense(200, activation='relu', input_shape=(4,)))\n",
    "NN.add(Dropout(0.5))\n",
    "NN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amontagut\\AppData\\Local\\Continuum\\miniconda2\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#Compile it\n",
    "\n",
    "NN.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 622 samples, validate on 208 samples\n",
      "WARNING:tensorflow:From C:\\Users\\amontagut\\AppData\\Local\\Continuum\\miniconda2\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.2229 - acc: 0.6479 - val_loss: 0.1875 - val_acc: 0.8269\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.1866 - acc: 0.7556 - val_loss: 0.1653 - val_acc: 0.8269\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.1757 - acc: 0.7830 - val_loss: 0.1503 - val_acc: 0.8462\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.1677 - acc: 0.7781 - val_loss: 0.1409 - val_acc: 0.8462\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.1602 - acc: 0.7814 - val_loss: 0.1355 - val_acc: 0.8413\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.1592 - acc: 0.7814 - val_loss: 0.1320 - val_acc: 0.8413\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.1549 - acc: 0.7781 - val_loss: 0.1281 - val_acc: 0.8413\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.1565 - acc: 0.7830 - val_loss: 0.1256 - val_acc: 0.8413\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.1553 - acc: 0.7942 - val_loss: 0.1245 - val_acc: 0.8413\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.1539 - acc: 0.7814 - val_loss: 0.1246 - val_acc: 0.8413\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.1549 - acc: 0.7749 - val_loss: 0.1237 - val_acc: 0.8365\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.1525 - acc: 0.7862 - val_loss: 0.1240 - val_acc: 0.8413\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.1523 - acc: 0.7862 - val_loss: 0.1237 - val_acc: 0.8365\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.1506 - acc: 0.7894 - val_loss: 0.1236 - val_acc: 0.8365\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.1498 - acc: 0.7862 - val_loss: 0.1229 - val_acc: 0.8365\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.1495 - acc: 0.7958 - val_loss: 0.1230 - val_acc: 0.8365\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.1525 - acc: 0.7878 - val_loss: 0.1225 - val_acc: 0.8365\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.1503 - acc: 0.7926 - val_loss: 0.1233 - val_acc: 0.8365\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.1500 - acc: 0.7814 - val_loss: 0.1228 - val_acc: 0.8365\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.1503 - acc: 0.7926 - val_loss: 0.1229 - val_acc: 0.8365\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.1498 - acc: 0.7926 - val_loss: 0.1231 - val_acc: 0.8365\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.1503 - acc: 0.7958 - val_loss: 0.1237 - val_acc: 0.8365\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.1496 - acc: 0.7974 - val_loss: 0.1234 - val_acc: 0.8413\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.1498 - acc: 0.7942 - val_loss: 0.1237 - val_acc: 0.8413\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.1489 - acc: 0.7958 - val_loss: 0.1230 - val_acc: 0.8413\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.1506 - acc: 0.7926 - val_loss: 0.1227 - val_acc: 0.8365\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.1504 - acc: 0.7878 - val_loss: 0.1229 - val_acc: 0.8365\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.1512 - acc: 0.7862 - val_loss: 0.1228 - val_acc: 0.8365\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.1468 - acc: 0.7910 - val_loss: 0.1230 - val_acc: 0.8413\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.1506 - acc: 0.7974 - val_loss: 0.1236 - val_acc: 0.8413\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.1472 - acc: 0.8023 - val_loss: 0.1237 - val_acc: 0.8413\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.1471 - acc: 0.7990 - val_loss: 0.1237 - val_acc: 0.8413\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.1502 - acc: 0.7894 - val_loss: 0.1235 - val_acc: 0.8413\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.1493 - acc: 0.7942 - val_loss: 0.1231 - val_acc: 0.8413\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.1487 - acc: 0.7942 - val_loss: 0.1227 - val_acc: 0.8413\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.1503 - acc: 0.7830 - val_loss: 0.1226 - val_acc: 0.8462\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.1483 - acc: 0.7958 - val_loss: 0.1229 - val_acc: 0.8462\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.1483 - acc: 0.7910 - val_loss: 0.1233 - val_acc: 0.8413\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.1468 - acc: 0.8023 - val_loss: 0.1230 - val_acc: 0.8413\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.1490 - acc: 0.7862 - val_loss: 0.1224 - val_acc: 0.8462\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.1472 - acc: 0.7990 - val_loss: 0.1233 - val_acc: 0.8462\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.1486 - acc: 0.7910 - val_loss: 0.1232 - val_acc: 0.8462\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.1463 - acc: 0.8055 - val_loss: 0.1238 - val_acc: 0.8510\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.1461 - acc: 0.7974 - val_loss: 0.1241 - val_acc: 0.8510\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.1483 - acc: 0.7926 - val_loss: 0.1248 - val_acc: 0.8462\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.1503 - acc: 0.7910 - val_loss: 0.1242 - val_acc: 0.8510\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.1465 - acc: 0.8006 - val_loss: 0.1241 - val_acc: 0.8510\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.1456 - acc: 0.7974 - val_loss: 0.1237 - val_acc: 0.8462\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1472 - acc: 0.7958 - val_loss: 0.1230 - val_acc: 0.8510\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1451 - acc: 0.7990 - val_loss: 0.1227 - val_acc: 0.8510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x122138f6e10>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the NN\n",
    "NN.fit(X_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_output = NN.predict(X_test)\n",
    "\n",
    "#Fit the NN output\n",
    "\n",
    "for x in range(len(NN_output)):\n",
    "    if NN_output[x] >= 0.5:\n",
    "        NN_output[x] = 1\n",
    "    else:\n",
    "        NN_output[x] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8509615384615384\n"
     ]
    }
   ],
   "source": [
    "#Evaluate accuracy\n",
    "\n",
    "NN_accuracy = accuracy_score(NN_output, y_test)\n",
    "\n",
    "print(NN_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Do we have a winner?\n",
    "\n",
    "Which model, and which choice of hyperparameters, performed the best? Feel free to share your results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
